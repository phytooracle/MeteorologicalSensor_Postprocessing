{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4499eec4-8058-457d-b043-c1f6caa37a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "import re\n",
    "import tarfile\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32966811-be1f-4155-9cca-aa61cdc0a996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these paths to point to the MeteorologicalSensor data locations on CyVerse for the target season\n",
    "cyverse_dir_l0 = \"/iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_0/MeteorologicalSensor\"\n",
    "cyverse_dir_l1 = \"/iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor\"\n",
    "cyverse_dir_l2 = \"/iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_2/MeteorologicalSensor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7855cf2-771b-4b23-9efc-2952fb272aa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Authorized uses only. All activity may be monitored and reported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D- ./MeteorologicalSensor :\n",
      "0/48 -  0.00% of files done   0.000/33.147 MB -  0.00% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-05-30__17-14-43-000_cotton.tar.gz - 0.749 MB   2025-12-19.09:30:25\n",
      "   MeteorologicalSensor-2025       0.749 MB | 0.970 sec | 0 thr |  0.772 MB/s\n",
      "1/48 -  2.08% of files done   0.749/33.147 MB -  2.26% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-05-30__23-10-02-000_cotton.tar.gz - 1.209 MB   2025-12-19.09:30:26\n",
      "   MeteorologicalSensor-2025       1.209 MB | 0.720 sec | 0 thr |  1.680 MB/s\n",
      "2/48 -  4.17% of files done   1.958/33.147 MB -  5.91% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-02__17-37-04-000_cotton.tar.gz - 0.751 MB   2025-12-19.09:30:27\n",
      "   MeteorologicalSensor-2025       0.751 MB | 0.346 sec | 0 thr |  2.169 MB/s\n",
      "3/48 -  6.25% of files done   2.709/33.147 MB -  8.17% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-05__17-27-49-000_cotton.tar.gz - 0.723 MB   2025-12-19.09:30:27\n",
      "   MeteorologicalSensor-2025       0.723 MB | 0.399 sec | 0 thr |  1.815 MB/s\n",
      "4/48 -  8.33% of files done   3.432/33.147 MB - 10.35% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-09__17-41-10-000_cotton.tar.gz - 0.596 MB   2025-12-19.09:30:28\n",
      "   MeteorologicalSensor-2025       0.596 MB | 0.355 sec | 0 thr |  1.681 MB/s\n",
      "5/48 - 10.42% of files done   4.029/33.147 MB - 12.15% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-13__18-06-09-000_cotton.tar.gz - 0.672 MB   2025-12-19.09:30:28\n",
      "   MeteorologicalSensor-2025       0.672 MB | 0.392 sec | 0 thr |  1.715 MB/s\n",
      "6/48 - 12.50% of files done   4.701/33.147 MB - 14.18% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-14__00-16-53-000_cotton.tar.gz - 1.104 MB   2025-12-19.09:30:28\n",
      "   MeteorologicalSensor-2025       1.104 MB | 0.347 sec | 0 thr |  3.178 MB/s\n",
      "7/48 - 14.58% of files done   5.805/33.147 MB - 17.51% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-16__17-27-21-000_cotton.tar.gz - 0.664 MB   2025-12-19.09:30:29\n",
      "   MeteorologicalSensor-2025       0.664 MB | 0.403 sec | 0 thr |  1.645 MB/s\n",
      "8/48 - 16.67% of files done   6.468/33.147 MB - 19.51% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-18__15-51-51-000_cotton.tar.gz - 1.119 MB   2025-12-19.09:30:29\n",
      "   MeteorologicalSensor-2025       1.119 MB | 0.735 sec | 0 thr |  1.523 MB/s\n",
      "9/48 - 18.75% of files done   7.588/33.147 MB - 22.89% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-19__18-09-05-000_cotton.tar.gz - 0.699 MB   2025-12-19.09:30:30\n",
      "   MeteorologicalSensor-2025       0.699 MB | 0.918 sec | 0 thr |  0.762 MB/s\n",
      "10/48 - 20.83% of files done   8.287/33.147 MB - 25.00% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-23__17-38-28-000_cotton.tar.gz - 0.666 MB   2025-12-19.09:30:31\n",
      "   MeteorologicalSensor-2025       0.666 MB | 0.429 sec | 0 thr |  1.551 MB/s\n",
      "11/48 - 22.92% of files done   8.952/33.147 MB - 27.01% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-25__15-16-37-000_cotton.tar.gz - 1.152 MB   2025-12-19.09:30:31\n",
      "   MeteorologicalSensor-2025       1.152 MB | 0.348 sec | 0 thr |  3.312 MB/s\n",
      "12/48 - 25.00% of files done   10.104/33.147 MB - 30.48% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-26__17-54-16-000_cotton.tar.gz - 0.699 MB   2025-12-19.09:30:32\n",
      "   MeteorologicalSensor-2025       0.699 MB | 0.365 sec | 0 thr |  1.918 MB/s\n",
      "13/48 - 27.08% of files done   10.803/33.147 MB - 32.59% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-06-30__17-29-09-000_cotton.tar.gz - 0.756 MB   2025-12-19.09:30:32\n",
      "   MeteorologicalSensor-2025       0.756 MB | 0.342 sec | 0 thr |  2.209 MB/s\n",
      "14/48 - 29.17% of files done   11.559/33.147 MB - 34.87% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-07-01__14-51-20-000_cotton.tar.gz - 1.132 MB   2025-12-19.09:30:32\n",
      "   MeteorologicalSensor-2025       1.132 MB | 0.503 sec | 0 thr |  2.252 MB/s\n",
      "15/48 - 31.25% of files done   12.692/33.147 MB - 38.29% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-07-03__17-33-44-000_cotton.tar.gz - 0.739 MB   2025-12-19.09:30:33\n",
      "   MeteorologicalSensor-2025       0.739 MB | 0.458 sec | 0 thr |  1.615 MB/s\n",
      "16/48 - 33.33% of files done   13.431/33.147 MB - 40.52% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-07-07__17-29-47-000_cotton.tar.gz - 0.645 MB   2025-12-19.09:30:33\n",
      "   MeteorologicalSensor-2025       0.645 MB | 0.377 sec | 0 thr |  1.711 MB/s\n",
      "17/48 - 35.42% of files done   14.075/33.147 MB - 42.46% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-07-10__17-42-32-000_cotton.tar.gz - 0.563 MB   2025-12-19.09:30:34\n",
      "   MeteorologicalSensor-2025       0.563 MB | 0.324 sec | 0 thr |  1.739 MB/s\n",
      "18/48 - 37.50% of files done   14.639/33.147 MB - 44.16% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-07-14__17-30-42-000_cotton.tar.gz - 0.578 MB   2025-12-19.09:30:34\n",
      "   MeteorologicalSensor-2025       0.578 MB | 0.441 sec | 0 thr |  1.312 MB/s\n",
      "19/48 - 39.58% of files done   15.217/33.147 MB - 45.91% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-07-16__17-27-47-000_cotton.tar.gz - 0.687 MB   2025-12-19.09:30:34\n",
      "   MeteorologicalSensor-2025       0.687 MB | 0.470 sec | 0 thr |  1.461 MB/s\n",
      "20/48 - 41.67% of files done   15.904/33.147 MB - 47.98% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-07-21__17-29-15-000_cotton.tar.gz - 0.619 MB   2025-12-19.09:30:35\n",
      "   MeteorologicalSensor-2025       0.619 MB | 0.439 sec | 0 thr |  1.410 MB/s\n",
      "21/48 - 43.75% of files done   16.522/33.147 MB - 49.84% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-07-24__04-54-57-000_cotton.tar.gz - 0.325 MB   2025-12-19.09:30:35\n",
      "   MeteorologicalSensor-2025       0.325 MB | 0.355 sec | 0 thr |  0.914 MB/s\n",
      "22/48 - 45.83% of files done   16.847/33.147 MB - 50.83% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-07-24__17-25-09-000_cotton.tar.gz - 0.661 MB   2025-12-19.09:30:36\n",
      "   MeteorologicalSensor-2025       0.661 MB | 0.354 sec | 0 thr |  1.870 MB/s\n",
      "23/48 - 47.92% of files done   17.509/33.147 MB - 52.82% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-07-25__05-03-06-000_cotton.tar.gz - 0.310 MB   2025-12-19.09:30:36\n",
      "   MeteorologicalSensor-2025       0.310 MB | 0.342 sec | 0 thr |  0.905 MB/s\n",
      "24/48 - 50.00% of files done   17.818/33.147 MB - 53.75% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-07-30__18-40-16-000_cotton.tar.gz - 0.754 MB   2025-12-19.09:30:36\n",
      "   MeteorologicalSensor-2025       0.754 MB | 0.421 sec | 0 thr |  1.793 MB/s\n",
      "25/48 - 52.08% of files done   18.573/33.147 MB - 56.03% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-08-01__17-29-20-000_cotton.tar.gz - 0.751 MB   2025-12-19.09:30:37\n",
      "   MeteorologicalSensor-2025       0.751 MB | 0.449 sec | 0 thr |  1.671 MB/s\n",
      "26/48 - 54.17% of files done   19.324/33.147 MB - 58.30% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-08-04__04-58-54-000_cotton.tar.gz - 0.375 MB   2025-12-19.09:30:37\n",
      "   MeteorologicalSensor-2025       0.375 MB | 0.341 sec | 0 thr |  1.099 MB/s\n",
      "27/48 - 56.25% of files done   19.699/33.147 MB - 59.43% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-08-04__17-28-08-000_cotton.tar.gz - 0.722 MB   2025-12-19.09:30:38\n",
      "   MeteorologicalSensor-2025       0.722 MB | 0.433 sec | 0 thr |  1.667 MB/s\n",
      "28/48 - 58.33% of files done   20.421/33.147 MB - 61.61% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-08-05__04-58-30-000_cotton.tar.gz - 0.357 MB   2025-12-19.09:30:38\n",
      "   MeteorologicalSensor-2025       0.357 MB | 0.375 sec | 0 thr |  0.951 MB/s\n",
      "29/48 - 60.42% of files done   20.778/33.147 MB - 62.68% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-08-08__17-27-29-000_cotton.tar.gz - 0.746 MB   2025-12-19.09:30:38\n",
      "   MeteorologicalSensor-2025       0.746 MB | 0.453 sec | 0 thr |  1.647 MB/s\n",
      "30/48 - 62.50% of files done   21.524/33.147 MB - 64.93% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-08-11__17-30-12-000_cotton.tar.gz - 0.756 MB   2025-12-19.09:30:39\n",
      "   MeteorologicalSensor-2025       0.756 MB | 0.403 sec | 0 thr |  1.876 MB/s\n",
      "31/48 - 64.58% of files done   22.280/33.147 MB - 67.21% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-08-14__04-58-19-000_cotton.tar.gz - 0.348 MB   2025-12-19.09:30:39\n",
      "   MeteorologicalSensor-2025       0.348 MB | 0.426 sec | 0 thr |  0.817 MB/s\n",
      "32/48 - 66.67% of files done   22.628/33.147 MB - 68.26% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-08-14__17-26-54-000_cotton.tar.gz - 0.792 MB   2025-12-19.09:30:40\n",
      "   MeteorologicalSensor-2025       0.792 MB | 0.421 sec | 0 thr |  1.882 MB/s\n",
      "33/48 - 68.75% of files done   23.419/33.147 MB - 70.65% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-08-15__04-57-00-000_cotton.tar.gz - 0.187 MB   2025-12-19.09:30:40\n",
      "   MeteorologicalSensor-2025       0.187 MB | 0.362 sec | 0 thr |  0.516 MB/s\n",
      "34/48 - 70.83% of files done   23.606/33.147 MB - 71.22% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-08-18__17-31-03-000_cotton.tar.gz - 0.815 MB   2025-12-19.09:30:40\n",
      "   MeteorologicalSensor-2025       0.815 MB | 0.378 sec | 0 thr |  2.158 MB/s\n",
      "35/48 - 72.92% of files done   24.421/33.147 MB - 73.67% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-08-22__17-32-06-000_cotton.tar.gz - 0.747 MB   2025-12-19.09:30:41\n",
      "   MeteorologicalSensor-2025       0.747 MB | 0.447 sec | 0 thr |  1.672 MB/s\n",
      "36/48 - 75.00% of files done   25.168/33.147 MB - 75.93% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-09-10__17-25-27-000_cotton.tar.gz - 0.749 MB   2025-12-19.09:30:41\n",
      "   MeteorologicalSensor-2025       0.749 MB | 0.405 sec | 0 thr |  1.847 MB/s\n",
      "37/48 - 77.08% of files done   25.917/33.147 MB - 78.19% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-09-11__17-20-09-000_cotton.tar.gz - 0.788 MB   2025-12-19.09:30:42\n",
      "   MeteorologicalSensor-2025       0.788 MB | 0.402 sec | 0 thr |  1.957 MB/s\n",
      "38/48 - 79.17% of files done   26.704/33.147 MB - 80.56% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-09-15__17-28-14-000_cotton.tar.gz - 0.726 MB   2025-12-19.09:30:42\n",
      "   MeteorologicalSensor-2025       0.726 MB | 0.373 sec | 0 thr |  1.945 MB/s\n",
      "39/48 - 81.25% of files done   27.430/33.147 MB - 82.75% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-09-18__16-59-50-000_cotton.tar.gz - 0.780 MB   2025-12-19.09:30:42\n",
      "   MeteorologicalSensor-2025       0.780 MB | 0.362 sec | 0 thr |  2.154 MB/s\n",
      "40/48 - 83.33% of files done   28.210/33.147 MB - 85.10% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-09-22__19-29-02-000_cotton.tar.gz - 0.697 MB   2025-12-19.09:30:43\n",
      "   MeteorologicalSensor-2025       0.697 MB | 0.378 sec | 0 thr |  1.844 MB/s\n",
      "41/48 - 85.42% of files done   28.907/33.147 MB - 87.21% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-09-24__17-29-20-000_cotton.tar.gz - 0.719 MB   2025-12-19.09:30:43\n",
      "   MeteorologicalSensor-2025       0.719 MB | 0.369 sec | 0 thr |  1.949 MB/s\n",
      "42/48 - 87.50% of files done   29.626/33.147 MB - 89.38% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-09-25__05-00-04-000_cotton.tar.gz - 0.300 MB   2025-12-19.09:30:44\n",
      "   MeteorologicalSensor-2025       0.300 MB | 0.376 sec | 0 thr |  0.797 MB/s\n",
      "43/48 - 89.58% of files done   29.926/33.147 MB - 90.28% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-09-26__04-56-17-000_cotton.tar.gz - 0.304 MB   2025-12-19.09:30:44\n",
      "   MeteorologicalSensor-2025       0.304 MB | 0.463 sec | 0 thr |  0.655 MB/s\n",
      "44/48 - 91.67% of files done   30.230/33.147 MB - 91.20% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-09-30__18-12-11-000_cotton.tar.gz - 0.714 MB   2025-12-19.09:30:44\n",
      "   MeteorologicalSensor-2025       0.714 MB | 0.413 sec | 0 thr |  1.727 MB/s\n",
      "45/48 - 93.75% of files done   30.943/33.147 MB - 93.35% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-10-02__17-49-04-000_cotton.tar.gz - 0.751 MB   2025-12-19.09:30:45\n",
      "   MeteorologicalSensor-2025       0.751 MB | 0.450 sec | 0 thr |  1.671 MB/s\n",
      "46/48 - 95.83% of files done   31.695/33.147 MB - 95.62% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-10-06__17-15-53-000_cotton.tar.gz - 0.722 MB   2025-12-19.09:30:45\n",
      "   MeteorologicalSensor-2025       0.722 MB | 0.360 sec | 0 thr |  2.004 MB/s\n",
      "47/48 - 97.92% of files done   32.416/33.147 MB - 97.79% of file sizes done\n",
      "Processing MeteorologicalSensor-2025-10-09__17-07-15-000_cotton.tar.gz - 0.731 MB   2025-12-19.09:30:46\n",
      "   MeteorologicalSensor-2025       0.731 MB | 0.385 sec | 0 thr |  1.897 MB/s\n",
      "None\n",
      "download complete\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "cmd1 = f'iget -rkPVT {cyverse_dir_l0}'\n",
    "download = sp.run(f\"ssh filexfer 'mkdir {cwd}/inputs && cd {cwd}/inputs && {cmd1} && exit'\", shell=True)\n",
    "print(download.stdout)\n",
    "print(\"download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889946b4-1f28-4501-8b1d-6d766978ed81",
   "metadata": {},
   "source": [
    "Above download dumps files in CWD/inputs/MeteorologicalSensor\n",
    "\n",
    "For each tarball, we want to extract the contents, and then merge the CSVs for all plots.\n",
    "\n",
    "Each tarball has the following tree:\n",
    "```\n",
    "MeteorologicalSensor-2025-05-30__17-14-43-000_cotton.tar.gz\n",
    ".\n",
    "└── MeteorologicalSensor-2025-05-30__17-14-43-000_cotton\n",
    "    ├── hdf5_extraction.log\n",
    "    └── meteorological_sensor\n",
    "        ├── 1\n",
    "        │   ├── epar_1_0_data.csv\n",
    "        │   ├── par_2_1_data.csv\n",
    "        │   └── weather_station_3_0_data.csv\n",
    "        ├── 2\n",
    "        │   ├── epar_1_0_data.csv\n",
    "        │   ├── par_2_1_data.csv\n",
    "        │   └── weather_station_3_0_data.csv\n",
    "        ├── ...        \n",
    "        └── N\n",
    "            ├── epar_1_0_data.csv\n",
    "            ├── par_2_1_data.csv\n",
    "            └── weather_station_3_0_data.csv\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98637837-00aa-4b9b-a0d8-b34cf7db6419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map logical sensor names to expected CSV filenames inside each plot folder\n",
    "SENSOR_FILES = {\n",
    "    \"epar\": \"epar_1_0_data.csv\",\n",
    "    \"par\": \"par_2_1_data.csv\",\n",
    "    \"weather_station\": \"weather_station_3_0_data.csv\",\n",
    "}\n",
    "\n",
    "TARBALL_NAME_RE = re.compile(\n",
    "    r\"\"\"\n",
    "    ^MeteorologicalSensor-        # prefix\n",
    "    (?P<date>\\d{4}-\\d{2}-\\d{2})   # YYYY-MM-DD\n",
    "    __\n",
    "    (?P<time>\\d{2}-\\d{2}-\\d{2}-\\d{3})  # HH-MM-SS-sss\n",
    "    _\n",
    "    (?P<crop>[A-Za-z0-9_-]+)      # crop name\n",
    "    \\.tar\\.gz$                    # suffix\n",
    "    \"\"\",\n",
    "    re.X,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7cd7b099-beb6-46be-8235-a1f2967e5b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_tarball_metadata(tar_path: Path) -> Dict[str, Optional[str]]:\n",
    "    \"\"\"\n",
    "    Extract metadata (date, time, crop, base_name) from tarball filename.\n",
    "    \"\"\"\n",
    "    name = tar_path.name\n",
    "    m = TARBALL_NAME_RE.match(name)\n",
    "    # Path.stem for .tar.gz yields stem='MeteorologicalSensor-...tar'\n",
    "    # Remove trailing '.tar' from the stem for a clean base name.\n",
    "    stem = tar_path.stem\n",
    "    base_name = stem[:-4] if stem.endswith(\".tar\") else stem\n",
    "\n",
    "    meta = {\n",
    "        \"tarball_name\": name,\n",
    "        \"base_name\": base_name,\n",
    "        \"date\": None,\n",
    "        \"time\": None,\n",
    "        \"crop\": None,\n",
    "    }\n",
    "    if m:\n",
    "        meta[\"date\"] = m.group(\"date\")\n",
    "        meta[\"time\"] = m.group(\"time\")\n",
    "        meta[\"crop\"] = m.group(\"crop\")\n",
    "    return meta\n",
    "\n",
    "\n",
    "def safe_extract(tar: tarfile.TarFile, path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Safely extract tarfile to 'path', preventing path traversal.\n",
    "    \"\"\"\n",
    "    path = path.resolve()\n",
    "    for member in tar.getmembers():\n",
    "        member_path = (path / member.name).resolve()\n",
    "        if not str(member_path).startswith(str(path)):\n",
    "            raise RuntimeError(f\"Blocked path traversal attempt: {member.name}\")\n",
    "    tar.extractall(path)\n",
    "\n",
    "\n",
    "def extract_tarball(tar_path: Path, work_dir: Path) -> Path:\n",
    "    \"\"\"\n",
    "    Extract tarball into work_dir/<base_name> and return the extraction root.\n",
    "\n",
    "    If the tar contains exactly one top-level directory, return that inner directory\n",
    "    to make downstream path handling simpler. Otherwise return the outer path.\n",
    "    \"\"\"\n",
    "    meta = parse_tarball_metadata(tar_path)\n",
    "    extract_root = work_dir / meta[\"base_name\"]\n",
    "    extract_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with tarfile.open(tar_path, \"r:gz\") as tf:\n",
    "        safe_extract(tf, extract_root)\n",
    "\n",
    "    # If there is exactly one top-level directory, return it for convenience\n",
    "    try:\n",
    "        top_dirs = [p for p in extract_root.iterdir() if p.is_dir()]\n",
    "        if len(top_dirs) == 1:\n",
    "            return top_dirs[0]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return extract_root\n",
    "\n",
    "\n",
    "def find_sensor_root(extract_root: Path) -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Locate the 'meteorological_sensor' directory under the extracted content,\n",
    "    even if it's nested (e.g., extract_root/<top>/meteorological_sensor).\n",
    "    \"\"\"\n",
    "    direct = extract_root / \"meteorological_sensor\"\n",
    "    if direct.exists():\n",
    "        return direct\n",
    "\n",
    "    candidates = list(extract_root.rglob(\"meteorological_sensor\"))\n",
    "    if candidates:\n",
    "        candidates.sort(key=lambda p: len(p.parts))  # shallowest first\n",
    "        return candidates[0]\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_plot_dirs(extract_root: Path) -> List[Path]:\n",
    "    \"\"\"\n",
    "    Find plot directories under .../meteorological_sensor/<plot_id>/.\n",
    "\n",
    "    A plot directory is valid if:\n",
    "      - It's a directory\n",
    "      - Its name is strictly numeric, e.g., '1', '2', ... 'N'\n",
    "    \"\"\"\n",
    "    sensor_root = find_sensor_root(extract_root)\n",
    "    if sensor_root is None:\n",
    "        print(f\"[WARN] 'meteorological_sensor' directory not found under {extract_root}\")\n",
    "        return []\n",
    "\n",
    "    plot_dirs: List[Path] = []\n",
    "    try:\n",
    "        for child in sensor_root.iterdir():\n",
    "            if child.is_dir() and child.name.isdigit():\n",
    "                plot_dirs.append(child)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to iterate {sensor_root}: {e}\")\n",
    "        return []\n",
    "\n",
    "    plot_dirs.sort(key=lambda p: int(p.name))\n",
    "\n",
    "    if not plot_dirs:\n",
    "        sample_children = []\n",
    "        try:\n",
    "            sample_children = [c.name for c in sensor_root.iterdir()]\n",
    "        except Exception:\n",
    "            pass\n",
    "        print(\n",
    "            \"[WARN] Found 'meteorological_sensor' at \"\n",
    "            f\"{sensor_root}, but no numeric plot dirs inside. \"\n",
    "            f\"Children: {sample_children[:10]}{' ...' if len(sample_children) > 10 else ''}\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"[INFO] Found {len(plot_dirs)} plot directories in {sensor_root}\")\n",
    "\n",
    "    return plot_dirs\n",
    "\n",
    "\n",
    "def find_sensor_csv_path(plot_dir: Path, expected_filename: str, sensor_name: str) -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Locate the sensor CSV within a plot directory.\n",
    "    Tries exact expected filename first, then falls back to a pattern like '{sensor_name}_*_data.csv'.\n",
    "    \"\"\"\n",
    "    exact = plot_dir / expected_filename\n",
    "    if exact.exists():\n",
    "        return exact\n",
    "    candidates = sorted(plot_dir.glob(f\"{sensor_name}_*_data.csv\"))\n",
    "    if candidates:\n",
    "        # Prefer the lexicographically smallest candidate for reproducibility\n",
    "        return candidates[0]\n",
    "    print(f\"[WARN] Could not find CSV for sensor '{sensor_name}' in {plot_dir}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def read_sensor_csv(csv_path: Path) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Robust CSV reader for semicolon-delimited files with a header in the first row.\n",
    "    Tries the C engine first (fast), falls back to Python engine (forgiving) without low_memory.\n",
    "    \"\"\"\n",
    "    if not csv_path or not csv_path.exists():\n",
    "        print(f\"[WARN] Missing expected CSV: {csv_path}\")\n",
    "        return None\n",
    "\n",
    "    # Attempt fast C engine\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            csv_path,\n",
    "            sep=\";\",\n",
    "            encoding=\"utf-8\",\n",
    "            low_memory=False,  # supported by C engine\n",
    "        )\n",
    "        return df\n",
    "    except Exception as e_c:\n",
    "        print(f\"[WARN] C engine failed for {csv_path}: {e_c}. Falling back to Python engine.\")\n",
    "\n",
    "    # Fallback to Python engine (do NOT pass low_memory)\n",
    "    try:\n",
    "        try:\n",
    "            df = pd.read_csv(\n",
    "                csv_path,\n",
    "                sep=\";\",\n",
    "                encoding=\"utf-8\",\n",
    "                engine=\"python\",\n",
    "                on_bad_lines=\"skip\",   # pandas >= 1.3\n",
    "            )\n",
    "        except TypeError:\n",
    "            # Older pandas fallback (pre-1.3)\n",
    "            df = pd.read_csv(\n",
    "                csv_path,\n",
    "                sep=\";\",\n",
    "                encoding=\"utf-8\",\n",
    "                engine=\"python\",\n",
    "                error_bad_lines=False,\n",
    "            )\n",
    "        return df\n",
    "    except Exception as e_py:\n",
    "        print(f\"[WARN] Python engine also failed for {csv_path}: {e_py}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def normalize_time_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a unified 'timestamp' column from 'date_int' (µs since epoch) or 'date' (YYYY-MM-DD_HH:MM:SS).\n",
    "    Fills NaT where parsing fails; leaves timezone-naive timestamps.\n",
    "    \"\"\"\n",
    "    ts = None\n",
    "\n",
    "    if \"date_int\" in df.columns:\n",
    "        try:\n",
    "            ts = pd.to_datetime(df[\"date_int\"].astype(\"int64\"), unit=\"us\", errors=\"coerce\")\n",
    "        except Exception:\n",
    "            ts = pd.to_datetime(df[\"date_int\"], unit=\"us\", errors=\"coerce\")\n",
    "\n",
    "    if ts is None or getattr(ts, \"isna\", lambda: True)().all():\n",
    "        if \"date\" in df.columns:\n",
    "            ts = pd.to_datetime(df[\"date\"], format=\"%Y-%m-%d_%H:%M:%S\", errors=\"coerce\")\n",
    "        else:\n",
    "            ts = pd.Series(pd.NaT, index=df.index)\n",
    "\n",
    "    df[\"timestamp\"] = ts\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_metadata_columns(df: pd.DataFrame, meta: Dict[str, Optional[str]], sensor_name: str, plot_id: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add collision-safe metadata columns:\n",
    "      - plot_id, sensor_type, tarball_name\n",
    "      - meta_date, meta_time, meta_crop\n",
    "    Ensures these columns exist; then reorders to place metadata first.\n",
    "    \"\"\"\n",
    "    # Assign (won't error if original df already has 'date')\n",
    "    df[\"plot_id\"] = plot_id\n",
    "    df[\"sensor_type\"] = sensor_name\n",
    "    df[\"tarball_name\"] = meta.get(\"tarball_name\")\n",
    "    df[\"meta_date\"] = meta.get(\"date\")\n",
    "    df[\"meta_time\"] = meta.get(\"time\")\n",
    "    df[\"meta_crop\"] = meta.get(\"crop\")\n",
    "\n",
    "    meta_cols = [\"plot_id\", \"sensor_type\", \"tarball_name\", \"meta_date\", \"meta_time\", \"meta_crop\"]\n",
    "    # Reorder: metadata first, then the rest\n",
    "    remaining = [c for c in df.columns if c not in meta_cols]\n",
    "    df = df[meta_cols + remaining]\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- Core merge logic ---------------------------------------------------------\n",
    "\n",
    "def merge_tarball(\n",
    "    tarball_path: Path,\n",
    "    extract_root: Path,\n",
    "    output_dir: Path,\n",
    "    dedupe_on_timestamp: bool = True,\n",
    "    make_long_format: bool = True,\n",
    ") -> Dict[str, Path]:\n",
    "    \"\"\"\n",
    "    Merge CSVs for all plots within a single tarball.\n",
    "    Returns dict of output file paths keyed by sensor name and 'all_sensors' if applicable.\n",
    "    \"\"\"\n",
    "    meta = parse_tarball_metadata(tarball_path)\n",
    "    plot_dirs = find_plot_dirs(extract_root)\n",
    "\n",
    "    if not plot_dirs:\n",
    "        print(f\"[WARN] No plot directories found for {tarball_path}\")\n",
    "        return {}\n",
    "\n",
    "    per_sensor_frames: Dict[str, List[pd.DataFrame]] = {k: [] for k in SENSOR_FILES.keys()}\n",
    "    long_frames: List[pd.DataFrame] = []\n",
    "\n",
    "    for plot_dir in plot_dirs:\n",
    "        plot_id = plot_dir.name\n",
    "\n",
    "        for sensor_name, expected_filename in SENSOR_FILES.items():\n",
    "            csv_path = find_sensor_csv_path(plot_dir, expected_filename, sensor_name)\n",
    "            df = read_sensor_csv(csv_path)\n",
    "            if df is None:\n",
    "                continue\n",
    "\n",
    "            # Normalize time columns for consistent dedupe/merge behavior\n",
    "            df = normalize_time_columns(df)\n",
    "\n",
    "            # Add collision-safe metadata columns\n",
    "            df = add_metadata_columns(df, meta, sensor_name, plot_id)\n",
    "\n",
    "            per_sensor_frames[sensor_name].append(df)\n",
    "            if make_long_format:\n",
    "                long_frames.append(df)\n",
    "\n",
    "    # Prepare output directory per tarball\n",
    "    out_dir = output_dir / meta[\"base_name\"]\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    outputs: Dict[str, Path] = {}\n",
    "\n",
    "    # Write per-sensor merged CSVs\n",
    "    for sensor_name, frames in per_sensor_frames.items():\n",
    "        if not frames:\n",
    "            continue\n",
    "        merged = pd.concat(frames, axis=0, ignore_index=True)\n",
    "\n",
    "        # Deduplication preferences: timestamp -> date_int -> date\n",
    "        if dedupe_on_timestamp:\n",
    "            if \"timestamp\" in merged.columns and merged[\"timestamp\"].notna().any():\n",
    "                merged = merged.drop_duplicates(subset=[\"plot_id\", \"timestamp\"])\n",
    "            elif \"date_int\" in merged.columns:\n",
    "                merged = merged.drop_duplicates(subset=[\"plot_id\", \"date_int\"])\n",
    "            elif \"date\" in merged.columns:\n",
    "                merged = merged.drop_duplicates(subset=[\"plot_id\", \"date\"])\n",
    "\n",
    "        out_path = out_dir / f\"{sensor_name}_merged.csv\"\n",
    "        merged.to_csv(out_path, index=False)\n",
    "        outputs[sensor_name] = out_path\n",
    "        print(f\"[INFO] Wrote {out_path} ({len(merged)} rows)\")\n",
    "\n",
    "    # Write long-format all-sensors merged CSV\n",
    "    if make_long_format and long_frames:\n",
    "        long_merged = pd.concat(long_frames, axis=0, ignore_index=True)\n",
    "        if dedupe_on_timestamp:\n",
    "            if \"timestamp\" in long_merged.columns and long_merged[\"timestamp\"].notna().any():\n",
    "                long_merged = long_merged.drop_duplicates(subset=[\"sensor_type\", \"plot_id\", \"timestamp\"])\n",
    "            elif \"date_int\" in long_merged.columns:\n",
    "                long_merged = long_merged.drop_duplicates(subset=[\"sensor_type\", \"plot_id\", \"date_int\"])\n",
    "            elif \"date\" in long_merged.columns:\n",
    "                long_merged = long_merged.drop_duplicates(subset=[\"sensor_type\", \"plot_id\", \"date\"])\n",
    "\n",
    "        out_path = out_dir / \"all_sensors_long.csv\"\n",
    "        long_merged.to_csv(out_path, index=False)\n",
    "        outputs[\"all_sensors\"] = out_path\n",
    "        print(f\"[INFO] Wrote {out_path} ({len(long_merged)} rows)\")\n",
    "\n",
    "    return outputs\n",
    "\n",
    "\n",
    "def process_all_tarballs(\n",
    "    input_dir: Path,\n",
    "    work_dir: Path,\n",
    "    output_dir: Path,\n",
    "    keep_extracted: bool = False,\n",
    "    make_global_merge: bool = False,\n",
    "    dedupe_on_timestamp: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Iterate over all *.tar.gz in input_dir, extract and merge per tarball.\n",
    "    Optionally, produce a global merged CSV across all tarballs for each sensor and for all sensors.\n",
    "    \"\"\"\n",
    "    # Strict Paths: callers should pass Path objects (Option B).\n",
    "    if not input_dir.exists():\n",
    "        raise FileNotFoundError(f\"Input dir not found: {input_dir}\")\n",
    "\n",
    "    work_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    tarballs = sorted(input_dir.glob(\"*.tar.gz\"))\n",
    "    if not tarballs:\n",
    "        print(f\"[INFO] No .tar.gz files found in {input_dir}\")\n",
    "        return\n",
    "\n",
    "    global_sensor_frames: Dict[str, List[pd.DataFrame]] = {k: [] for k in SENSOR_FILES.keys()}\n",
    "    global_long_frames: List[pd.DataFrame] = []\n",
    "\n",
    "    for tar in tarballs:\n",
    "        print(f\"[INFO] Processing {tar.name} ...\")\n",
    "        extract_root = extract_tarball(tar, work_dir)\n",
    "\n",
    "        # Optional debug: show where the script is looking\n",
    "        sensor_root = find_sensor_root(extract_root)\n",
    "        print(f\"[DEBUG] sensor_root: {sensor_root}\")\n",
    "\n",
    "        outputs = merge_tarball(\n",
    "            tarball_path=tar,\n",
    "            extract_root=extract_root,\n",
    "            output_dir=output_dir,\n",
    "            dedupe_on_timestamp=dedupe_on_timestamp,\n",
    "            make_long_format=True,\n",
    "        )\n",
    "\n",
    "        # Accumulate for global merges\n",
    "        for sensor_name in SENSOR_FILES.keys():\n",
    "            out_path = outputs.get(sensor_name)\n",
    "            if out_path and out_path.exists():\n",
    "                # Read back with semicolon? No—these are our outputs, so they are comma CSVs from pandas.\n",
    "                df = pd.read_csv(out_path, low_memory=False)\n",
    "                global_sensor_frames[sensor_name].append(df)\n",
    "\n",
    "        if outputs.get(\"all_sensors\") and outputs[\"all_sensors\"].exists():\n",
    "            df_long = pd.read_csv(outputs[\"all_sensors\"], low_memory=False)\n",
    "            global_long_frames.append(df_long)\n",
    "\n",
    "        # Clean up extracted content if requested\n",
    "        if not keep_extracted:\n",
    "            try:\n",
    "                for root, dirs, files in os.walk(extract_root, topdown=False):\n",
    "                    for f in files:\n",
    "                        Path(root, f).unlink(missing_ok=True)\n",
    "                    for d in dirs:\n",
    "                        Path(root, d).rmdir()\n",
    "                Path(extract_root).rmdir()\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Failed to remove {extract_root}: {e}\")\n",
    "\n",
    "    # Create global merges\n",
    "    if make_global_merge:\n",
    "        global_dir = output_dir / \"_GLOBAL\"\n",
    "        global_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Per-sensor global merges\n",
    "        for sensor_name, frames in global_sensor_frames.items():\n",
    "            if not frames:\n",
    "                continue\n",
    "            merged = pd.concat(frames, axis=0, ignore_index=True)\n",
    "            if dedupe_on_timestamp:\n",
    "                if \"timestamp\" in merged.columns and merged[\"timestamp\"].notna().any():\n",
    "                    merged = merged.drop_duplicates(subset=[\"tarball_name\", \"plot_id\", \"timestamp\"])\n",
    "                elif \"date_int\" in merged.columns:\n",
    "                    merged = merged.drop_duplicates(subset=[\"tarball_name\", \"plot_id\", \"date_int\"])\n",
    "                elif \"date\" in merged.columns:\n",
    "                    merged = merged.drop_duplicates(subset=[\"tarball_name\", \"plot_id\", \"date\"])\n",
    "            out_path = global_dir / f\"{sensor_name}_GLOBAL_merged.csv\"\n",
    "            merged.to_csv(out_path, index=False)\n",
    "            print(f\"[INFO] Wrote {out_path} ({len(merged)} rows)\")\n",
    "\n",
    "        # All-sensors long global merge\n",
    "        if global_long_frames:\n",
    "            merged = pd.concat(global_long_frames, axis=0, ignore_index=True)\n",
    "            if dedupe_on_timestamp:\n",
    "                if \"timestamp\" in merged.columns and merged[\"timestamp\"].notna().any():\n",
    "                    merged = merged.drop_duplicates(subset=[\"tarball_name\", \"sensor_type\", \"plot_id\", \"timestamp\"])\n",
    "                elif \"date_int\" in merged.columns:\n",
    "                    merged = merged.drop_duplicates(subset=[\"tarball_name\", \"sensor_type\", \"plot_id\", \"date_int\"])\n",
    "                elif \"date\" in merged.columns:\n",
    "                    merged = merged.drop_duplicates(subset=[\"tarball_name\", \"sensor_type\", \"plot_id\", \"date\"])\n",
    "            out_path = global_dir / \"all_sensors_GLOBAL_long.csv\"\n",
    "            merged.to_csv(out_path, index=False)\n",
    "            print(f\"[INFO] Wrote {out_path} ({len(merged)} rows)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "71f830df-f954-40ee-a85a-95b34f3ac276",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./workdir', exist_ok=True)\n",
    "os.makedirs('./outputs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d298bac7-9d20-4616-a9ff-d4ff83d67425",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Processing MeteorologicalSensor-2025-05-30__17-14-43-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-05-30__17-14-43-000_cotton/MeteorologicalSensor-2025-05-30__17-14-43-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-05-30__17-14-43-000_cotton/MeteorologicalSensor-2025-05-30__17-14-43-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-05-30__17-14-43-000_cotton/epar_merged.csv (10985 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-05-30__17-14-43-000_cotton/par_merged.csv (10986 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-05-30__17-14-43-000_cotton/weather_station_merged.csv (943 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-05-30__17-14-43-000_cotton/all_sensors_long.csv (22914 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-05-30__23-10-02-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-05-30__23-10-02-000_cotton/MeteorologicalSensor-2025-05-30__23-10-02-000_cotton/meteorological_sensor\n",
      "[INFO] Found 296 plot directories in workdir/MeteorologicalSensor-2025-05-30__23-10-02-000_cotton/MeteorologicalSensor-2025-05-30__23-10-02-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-05-30__23-10-02-000_cotton/epar_merged.csv (19013 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-05-30__23-10-02-000_cotton/par_merged.csv (19001 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-05-30__23-10-02-000_cotton/weather_station_merged.csv (1625 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-05-30__23-10-02-000_cotton/all_sensors_long.csv (39639 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-02__17-37-04-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-02__17-37-04-000_cotton/MeteorologicalSensor-2025-06-02__17-37-04-000_cotton/meteorological_sensor\n",
      "[INFO] Found 163 plot directories in workdir/MeteorologicalSensor-2025-06-02__17-37-04-000_cotton/MeteorologicalSensor-2025-06-02__17-37-04-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-02__17-37-04-000_cotton/epar_merged.csv (10790 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-02__17-37-04-000_cotton/par_merged.csv (10777 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-02__17-37-04-000_cotton/weather_station_merged.csv (935 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-02__17-37-04-000_cotton/all_sensors_long.csv (22502 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-05__17-27-49-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-05__17-27-49-000_cotton/MeteorologicalSensor-2025-06-05__17-27-49-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-06-05__17-27-49-000_cotton/MeteorologicalSensor-2025-06-05__17-27-49-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-05__17-27-49-000_cotton/epar_merged.csv (10981 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-05__17-27-49-000_cotton/par_merged.csv (10980 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-05__17-27-49-000_cotton/weather_station_merged.csv (947 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-05__17-27-49-000_cotton/all_sensors_long.csv (22908 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-09__17-41-10-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-09__17-41-10-000_cotton/MeteorologicalSensor-2025-06-09__17-41-10-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-06-09__17-41-10-000_cotton/MeteorologicalSensor-2025-06-09__17-41-10-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-09__17-41-10-000_cotton/epar_merged.csv (10977 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-09__17-41-10-000_cotton/par_merged.csv (10971 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-09__17-41-10-000_cotton/weather_station_merged.csv (942 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-09__17-41-10-000_cotton/all_sensors_long.csv (22890 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-13__18-06-09-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-13__18-06-09-000_cotton/MeteorologicalSensor-2025-06-13__18-06-09-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-06-13__18-06-09-000_cotton/MeteorologicalSensor-2025-06-13__18-06-09-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-13__18-06-09-000_cotton/epar_merged.csv (10985 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-13__18-06-09-000_cotton/par_merged.csv (10984 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-13__18-06-09-000_cotton/weather_station_merged.csv (955 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-13__18-06-09-000_cotton/all_sensors_long.csv (22924 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-14__00-16-53-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-14__00-16-53-000_cotton/MeteorologicalSensor-2025-06-14__00-16-53-000_cotton/meteorological_sensor\n",
      "[INFO] Found 297 plot directories in workdir/MeteorologicalSensor-2025-06-14__00-16-53-000_cotton/MeteorologicalSensor-2025-06-14__00-16-53-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-14__00-16-53-000_cotton/epar_merged.csv (19071 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-14__00-16-53-000_cotton/par_merged.csv (19052 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-14__00-16-53-000_cotton/weather_station_merged.csv (1644 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-14__00-16-53-000_cotton/all_sensors_long.csv (39767 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-16__17-27-21-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-16__17-27-21-000_cotton/MeteorologicalSensor-2025-06-16__17-27-21-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-06-16__17-27-21-000_cotton/MeteorologicalSensor-2025-06-16__17-27-21-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-16__17-27-21-000_cotton/epar_merged.csv (10983 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-16__17-27-21-000_cotton/par_merged.csv (10976 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-16__17-27-21-000_cotton/weather_station_merged.csv (956 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-16__17-27-21-000_cotton/all_sensors_long.csv (22915 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-18__15-51-51-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-18__15-51-51-000_cotton/MeteorologicalSensor-2025-06-18__15-51-51-000_cotton/meteorological_sensor\n",
      "[INFO] Found 297 plot directories in workdir/MeteorologicalSensor-2025-06-18__15-51-51-000_cotton/MeteorologicalSensor-2025-06-18__15-51-51-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-18__15-51-51-000_cotton/epar_merged.csv (19084 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-18__15-51-51-000_cotton/par_merged.csv (19071 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-18__15-51-51-000_cotton/weather_station_merged.csv (1641 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-18__15-51-51-000_cotton/all_sensors_long.csv (39796 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-19__18-09-05-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-19__18-09-05-000_cotton/MeteorologicalSensor-2025-06-19__18-09-05-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-06-19__18-09-05-000_cotton/MeteorologicalSensor-2025-06-19__18-09-05-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-19__18-09-05-000_cotton/epar_merged.csv (10975 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-19__18-09-05-000_cotton/par_merged.csv (10973 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-19__18-09-05-000_cotton/weather_station_merged.csv (954 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-19__18-09-05-000_cotton/all_sensors_long.csv (22902 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-23__17-38-28-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-23__17-38-28-000_cotton/MeteorologicalSensor-2025-06-23__17-38-28-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-06-23__17-38-28-000_cotton/MeteorologicalSensor-2025-06-23__17-38-28-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-23__17-38-28-000_cotton/epar_merged.csv (10988 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-23__17-38-28-000_cotton/par_merged.csv (10989 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-23__17-38-28-000_cotton/weather_station_merged.csv (950 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-23__17-38-28-000_cotton/all_sensors_long.csv (22927 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-25__15-16-37-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-25__15-16-37-000_cotton/MeteorologicalSensor-2025-06-25__15-16-37-000_cotton/meteorological_sensor\n",
      "[INFO] Found 297 plot directories in workdir/MeteorologicalSensor-2025-06-25__15-16-37-000_cotton/MeteorologicalSensor-2025-06-25__15-16-37-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-25__15-16-37-000_cotton/epar_merged.csv (19060 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-25__15-16-37-000_cotton/par_merged.csv (19092 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-25__15-16-37-000_cotton/weather_station_merged.csv (1635 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-25__15-16-37-000_cotton/all_sensors_long.csv (39787 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-26__17-54-16-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-26__17-54-16-000_cotton/MeteorologicalSensor-2025-06-26__17-54-16-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-06-26__17-54-16-000_cotton/MeteorologicalSensor-2025-06-26__17-54-16-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-26__17-54-16-000_cotton/epar_merged.csv (10975 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-26__17-54-16-000_cotton/par_merged.csv (10977 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-26__17-54-16-000_cotton/weather_station_merged.csv (942 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-26__17-54-16-000_cotton/all_sensors_long.csv (22894 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-06-30__17-29-09-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-06-30__17-29-09-000_cotton/MeteorologicalSensor-2025-06-30__17-29-09-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-06-30__17-29-09-000_cotton/MeteorologicalSensor-2025-06-30__17-29-09-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-30__17-29-09-000_cotton/epar_merged.csv (10977 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-30__17-29-09-000_cotton/par_merged.csv (10981 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-30__17-29-09-000_cotton/weather_station_merged.csv (952 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-06-30__17-29-09-000_cotton/all_sensors_long.csv (22910 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-07-01__14-51-20-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-07-01__14-51-20-000_cotton/MeteorologicalSensor-2025-07-01__14-51-20-000_cotton/meteorological_sensor\n",
      "[INFO] Found 297 plot directories in workdir/MeteorologicalSensor-2025-07-01__14-51-20-000_cotton/MeteorologicalSensor-2025-07-01__14-51-20-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-01__14-51-20-000_cotton/epar_merged.csv (19066 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-01__14-51-20-000_cotton/par_merged.csv (19072 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-01__14-51-20-000_cotton/weather_station_merged.csv (1647 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-01__14-51-20-000_cotton/all_sensors_long.csv (39785 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-07-03__17-33-44-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-07-03__17-33-44-000_cotton/MeteorologicalSensor-2025-07-03__17-33-44-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-07-03__17-33-44-000_cotton/MeteorologicalSensor-2025-07-03__17-33-44-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-03__17-33-44-000_cotton/epar_merged.csv (10991 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-03__17-33-44-000_cotton/par_merged.csv (10988 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-03__17-33-44-000_cotton/weather_station_merged.csv (951 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-03__17-33-44-000_cotton/all_sensors_long.csv (22930 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-07-07__17-29-47-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-07-07__17-29-47-000_cotton/MeteorologicalSensor-2025-07-07__17-29-47-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-07-07__17-29-47-000_cotton/MeteorologicalSensor-2025-07-07__17-29-47-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-07__17-29-47-000_cotton/epar_merged.csv (10980 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-07__17-29-47-000_cotton/par_merged.csv (10979 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-07__17-29-47-000_cotton/weather_station_merged.csv (950 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-07__17-29-47-000_cotton/all_sensors_long.csv (22909 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-07-10__17-42-32-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-07-10__17-42-32-000_cotton/MeteorologicalSensor-2025-07-10__17-42-32-000_cotton/meteorological_sensor\n",
      "[INFO] Found 162 plot directories in workdir/MeteorologicalSensor-2025-07-10__17-42-32-000_cotton/MeteorologicalSensor-2025-07-10__17-42-32-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-10__17-42-32-000_cotton/epar_merged.csv (10716 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-10__17-42-32-000_cotton/par_merged.csv (10722 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-10__17-42-32-000_cotton/weather_station_merged.csv (931 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-10__17-42-32-000_cotton/all_sensors_long.csv (22369 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-07-14__17-30-42-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-07-14__17-30-42-000_cotton/MeteorologicalSensor-2025-07-14__17-30-42-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-07-14__17-30-42-000_cotton/MeteorologicalSensor-2025-07-14__17-30-42-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-14__17-30-42-000_cotton/epar_merged.csv (10979 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-14__17-30-42-000_cotton/par_merged.csv (10977 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-14__17-30-42-000_cotton/weather_station_merged.csv (958 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-14__17-30-42-000_cotton/all_sensors_long.csv (22914 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-07-16__17-27-47-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-07-16__17-27-47-000_cotton/MeteorologicalSensor-2025-07-16__17-27-47-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-07-16__17-27-47-000_cotton/MeteorologicalSensor-2025-07-16__17-27-47-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-16__17-27-47-000_cotton/epar_merged.csv (10974 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-16__17-27-47-000_cotton/par_merged.csv (10990 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-16__17-27-47-000_cotton/weather_station_merged.csv (951 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-16__17-27-47-000_cotton/all_sensors_long.csv (22915 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-07-21__17-29-15-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-07-21__17-29-15-000_cotton/MeteorologicalSensor-2025-07-21__17-29-15-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-07-21__17-29-15-000_cotton/MeteorologicalSensor-2025-07-21__17-29-15-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-21__17-29-15-000_cotton/epar_merged.csv (10973 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-21__17-29-15-000_cotton/par_merged.csv (10970 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-21__17-29-15-000_cotton/weather_station_merged.csv (949 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-21__17-29-15-000_cotton/all_sensors_long.csv (22892 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-07-24__04-54-57-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-07-24__04-54-57-000_cotton/MeteorologicalSensor-2025-07-24__04-54-57-000_cotton/meteorological_sensor\n",
      "[INFO] Found 442 plot directories in workdir/MeteorologicalSensor-2025-07-24__04-54-57-000_cotton/MeteorologicalSensor-2025-07-24__04-54-57-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-24__04-54-57-000_cotton/epar_merged.csv (4894 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-24__04-54-57-000_cotton/par_merged.csv (4899 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-24__04-54-57-000_cotton/weather_station_merged.csv (89 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-24__04-54-57-000_cotton/all_sensors_long.csv (9882 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-07-24__17-25-09-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-07-24__17-25-09-000_cotton/MeteorologicalSensor-2025-07-24__17-25-09-000_cotton/meteorological_sensor\n",
      "[INFO] Found 156 plot directories in workdir/MeteorologicalSensor-2025-07-24__17-25-09-000_cotton/MeteorologicalSensor-2025-07-24__17-25-09-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-24__17-25-09-000_cotton/epar_merged.csv (10332 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-24__17-25-09-000_cotton/par_merged.csv (10331 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-24__17-25-09-000_cotton/weather_station_merged.csv (894 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-24__17-25-09-000_cotton/all_sensors_long.csv (21557 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-07-25__05-03-06-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-07-25__05-03-06-000_cotton/MeteorologicalSensor-2025-07-25__05-03-06-000_cotton/meteorological_sensor\n",
      "[INFO] Found 425 plot directories in workdir/MeteorologicalSensor-2025-07-25__05-03-06-000_cotton/MeteorologicalSensor-2025-07-25__05-03-06-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-25__05-03-06-000_cotton/epar_merged.csv (4384 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-25__05-03-06-000_cotton/par_merged.csv (4357 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-25__05-03-06-000_cotton/weather_station_merged.csv (48 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-25__05-03-06-000_cotton/all_sensors_long.csv (8789 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-07-30__18-40-16-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-07-30__18-40-16-000_cotton/MeteorologicalSensor-2025-07-30__18-40-16-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-07-30__18-40-16-000_cotton/MeteorologicalSensor-2025-07-30__18-40-16-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-30__18-40-16-000_cotton/epar_merged.csv (10981 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-30__18-40-16-000_cotton/par_merged.csv (10980 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-30__18-40-16-000_cotton/weather_station_merged.csv (947 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-07-30__18-40-16-000_cotton/all_sensors_long.csv (22908 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-08-01__17-29-20-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-08-01__17-29-20-000_cotton/MeteorologicalSensor-2025-08-01__17-29-20-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-08-01__17-29-20-000_cotton/MeteorologicalSensor-2025-08-01__17-29-20-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-01__17-29-20-000_cotton/epar_merged.csv (10985 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-01__17-29-20-000_cotton/par_merged.csv (10975 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-01__17-29-20-000_cotton/weather_station_merged.csv (949 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-01__17-29-20-000_cotton/all_sensors_long.csv (22909 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-08-04__04-58-54-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-08-04__04-58-54-000_cotton/MeteorologicalSensor-2025-08-04__04-58-54-000_cotton/meteorological_sensor\n",
      "[INFO] Found 442 plot directories in workdir/MeteorologicalSensor-2025-08-04__04-58-54-000_cotton/MeteorologicalSensor-2025-08-04__04-58-54-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-04__04-58-54-000_cotton/epar_merged.csv (5223 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-04__04-58-54-000_cotton/par_merged.csv (5196 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-04__04-58-54-000_cotton/weather_station_merged.csv (118 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-04__04-58-54-000_cotton/all_sensors_long.csv (10537 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-08-04__17-28-08-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-08-04__17-28-08-000_cotton/MeteorologicalSensor-2025-08-04__17-28-08-000_cotton/meteorological_sensor\n",
      "[INFO] Found 165 plot directories in workdir/MeteorologicalSensor-2025-08-04__17-28-08-000_cotton/MeteorologicalSensor-2025-08-04__17-28-08-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-04__17-28-08-000_cotton/epar_merged.csv (10915 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-04__17-28-08-000_cotton/par_merged.csv (10910 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-04__17-28-08-000_cotton/weather_station_merged.csv (938 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-04__17-28-08-000_cotton/all_sensors_long.csv (22763 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-08-05__04-58-30-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-08-05__04-58-30-000_cotton/MeteorologicalSensor-2025-08-05__04-58-30-000_cotton/meteorological_sensor\n",
      "[INFO] Found 442 plot directories in workdir/MeteorologicalSensor-2025-08-05__04-58-30-000_cotton/MeteorologicalSensor-2025-08-05__04-58-30-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-05__04-58-30-000_cotton/epar_merged.csv (4935 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-05__04-58-30-000_cotton/par_merged.csv (4884 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-05__04-58-30-000_cotton/weather_station_merged.csv (95 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-05__04-58-30-000_cotton/all_sensors_long.csv (9914 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-08-08__17-27-29-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-08-08__17-27-29-000_cotton/MeteorologicalSensor-2025-08-08__17-27-29-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-08-08__17-27-29-000_cotton/MeteorologicalSensor-2025-08-08__17-27-29-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-08__17-27-29-000_cotton/epar_merged.csv (10987 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-08__17-27-29-000_cotton/par_merged.csv (10980 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-08__17-27-29-000_cotton/weather_station_merged.csv (953 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-08__17-27-29-000_cotton/all_sensors_long.csv (22920 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-08-11__17-30-12-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-08-11__17-30-12-000_cotton/MeteorologicalSensor-2025-08-11__17-30-12-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-08-11__17-30-12-000_cotton/MeteorologicalSensor-2025-08-11__17-30-12-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-11__17-30-12-000_cotton/epar_merged.csv (10985 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-11__17-30-12-000_cotton/par_merged.csv (10975 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-11__17-30-12-000_cotton/weather_station_merged.csv (955 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-11__17-30-12-000_cotton/all_sensors_long.csv (22915 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-08-14__04-58-19-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-08-14__04-58-19-000_cotton/MeteorologicalSensor-2025-08-14__04-58-19-000_cotton/meteorological_sensor\n",
      "[INFO] Found 442 plot directories in workdir/MeteorologicalSensor-2025-08-14__04-58-19-000_cotton/MeteorologicalSensor-2025-08-14__04-58-19-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-14__04-58-19-000_cotton/epar_merged.csv (4930 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-14__04-58-19-000_cotton/par_merged.csv (4889 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-14__04-58-19-000_cotton/weather_station_merged.csv (88 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-14__04-58-19-000_cotton/all_sensors_long.csv (9907 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-08-14__17-26-54-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-08-14__17-26-54-000_cotton/MeteorologicalSensor-2025-08-14__17-26-54-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-08-14__17-26-54-000_cotton/MeteorologicalSensor-2025-08-14__17-26-54-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-14__17-26-54-000_cotton/epar_merged.csv (10993 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-14__17-26-54-000_cotton/par_merged.csv (10980 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-14__17-26-54-000_cotton/weather_station_merged.csv (949 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-14__17-26-54-000_cotton/all_sensors_long.csv (22922 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-08-15__04-57-00-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-08-15__04-57-00-000_cotton/MeteorologicalSensor-2025-08-15__04-57-00-000_cotton/meteorological_sensor\n",
      "[INFO] Found 255 plot directories in workdir/MeteorologicalSensor-2025-08-15__04-57-00-000_cotton/MeteorologicalSensor-2025-08-15__04-57-00-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-15__04-57-00-000_cotton/epar_merged.csv (2762 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-15__04-57-00-000_cotton/par_merged.csv (2756 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-15__04-57-00-000_cotton/weather_station_merged.csv (44 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-15__04-57-00-000_cotton/all_sensors_long.csv (5562 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-08-18__17-31-03-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-08-18__17-31-03-000_cotton/MeteorologicalSensor-2025-08-18__17-31-03-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-08-18__17-31-03-000_cotton/MeteorologicalSensor-2025-08-18__17-31-03-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-18__17-31-03-000_cotton/epar_merged.csv (10976 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-18__17-31-03-000_cotton/par_merged.csv (10977 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-18__17-31-03-000_cotton/weather_station_merged.csv (943 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-18__17-31-03-000_cotton/all_sensors_long.csv (22896 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-08-22__17-32-06-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-08-22__17-32-06-000_cotton/MeteorologicalSensor-2025-08-22__17-32-06-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-08-22__17-32-06-000_cotton/MeteorologicalSensor-2025-08-22__17-32-06-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-22__17-32-06-000_cotton/epar_merged.csv (10983 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-22__17-32-06-000_cotton/par_merged.csv (10978 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-22__17-32-06-000_cotton/weather_station_merged.csv (948 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-08-22__17-32-06-000_cotton/all_sensors_long.csv (22909 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-09-10__17-25-27-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-09-10__17-25-27-000_cotton/MeteorologicalSensor-2025-09-10__17-25-27-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-09-10__17-25-27-000_cotton/MeteorologicalSensor-2025-09-10__17-25-27-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-10__17-25-27-000_cotton/epar_merged.csv (10938 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-10__17-25-27-000_cotton/par_merged.csv (10937 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-10__17-25-27-000_cotton/weather_station_merged.csv (948 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-10__17-25-27-000_cotton/all_sensors_long.csv (22823 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-09-11__17-20-09-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-09-11__17-20-09-000_cotton/MeteorologicalSensor-2025-09-11__17-20-09-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-09-11__17-20-09-000_cotton/MeteorologicalSensor-2025-09-11__17-20-09-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-11__17-20-09-000_cotton/epar_merged.csv (10985 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-11__17-20-09-000_cotton/par_merged.csv (10977 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-11__17-20-09-000_cotton/weather_station_merged.csv (947 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-11__17-20-09-000_cotton/all_sensors_long.csv (22909 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-09-15__17-28-14-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-09-15__17-28-14-000_cotton/MeteorologicalSensor-2025-09-15__17-28-14-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-09-15__17-28-14-000_cotton/MeteorologicalSensor-2025-09-15__17-28-14-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-15__17-28-14-000_cotton/epar_merged.csv (10984 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-15__17-28-14-000_cotton/par_merged.csv (10992 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-15__17-28-14-000_cotton/weather_station_merged.csv (950 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-15__17-28-14-000_cotton/all_sensors_long.csv (22926 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-09-18__16-59-50-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-09-18__16-59-50-000_cotton/MeteorologicalSensor-2025-09-18__16-59-50-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-09-18__16-59-50-000_cotton/MeteorologicalSensor-2025-09-18__16-59-50-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-18__16-59-50-000_cotton/epar_merged.csv (10987 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-18__16-59-50-000_cotton/par_merged.csv (10992 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-18__16-59-50-000_cotton/weather_station_merged.csv (946 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-18__16-59-50-000_cotton/all_sensors_long.csv (22925 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-09-22__19-29-02-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-09-22__19-29-02-000_cotton/MeteorologicalSensor-2025-09-22__19-29-02-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-09-22__19-29-02-000_cotton/MeteorologicalSensor-2025-09-22__19-29-02-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-22__19-29-02-000_cotton/epar_merged.csv (10975 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-22__19-29-02-000_cotton/par_merged.csv (10977 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-22__19-29-02-000_cotton/weather_station_merged.csv (945 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-22__19-29-02-000_cotton/all_sensors_long.csv (22897 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-09-24__17-29-20-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-09-24__17-29-20-000_cotton/MeteorologicalSensor-2025-09-24__17-29-20-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-09-24__17-29-20-000_cotton/MeteorologicalSensor-2025-09-24__17-29-20-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-24__17-29-20-000_cotton/epar_merged.csv (10975 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-24__17-29-20-000_cotton/par_merged.csv (10980 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-24__17-29-20-000_cotton/weather_station_merged.csv (949 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-24__17-29-20-000_cotton/all_sensors_long.csv (22904 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-09-25__05-00-04-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-09-25__05-00-04-000_cotton/MeteorologicalSensor-2025-09-25__05-00-04-000_cotton/meteorological_sensor\n",
      "[INFO] Found 442 plot directories in workdir/MeteorologicalSensor-2025-09-25__05-00-04-000_cotton/MeteorologicalSensor-2025-09-25__05-00-04-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-25__05-00-04-000_cotton/epar_merged.csv (4907 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-25__05-00-04-000_cotton/par_merged.csv (4900 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-25__05-00-04-000_cotton/weather_station_merged.csv (90 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-25__05-00-04-000_cotton/all_sensors_long.csv (9897 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-09-26__04-56-17-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-09-26__04-56-17-000_cotton/MeteorologicalSensor-2025-09-26__04-56-17-000_cotton/meteorological_sensor\n",
      "[INFO] Found 442 plot directories in workdir/MeteorologicalSensor-2025-09-26__04-56-17-000_cotton/MeteorologicalSensor-2025-09-26__04-56-17-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-26__04-56-17-000_cotton/epar_merged.csv (4929 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-26__04-56-17-000_cotton/par_merged.csv (4899 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-26__04-56-17-000_cotton/weather_station_merged.csv (100 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-26__04-56-17-000_cotton/all_sensors_long.csv (9928 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-09-30__18-12-11-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-09-30__18-12-11-000_cotton/MeteorologicalSensor-2025-09-30__18-12-11-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-09-30__18-12-11-000_cotton/MeteorologicalSensor-2025-09-30__18-12-11-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-30__18-12-11-000_cotton/epar_merged.csv (10975 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-30__18-12-11-000_cotton/par_merged.csv (10981 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-30__18-12-11-000_cotton/weather_station_merged.csv (950 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-09-30__18-12-11-000_cotton/all_sensors_long.csv (22906 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-10-02__17-49-04-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-10-02__17-49-04-000_cotton/MeteorologicalSensor-2025-10-02__17-49-04-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-10-02__17-49-04-000_cotton/MeteorologicalSensor-2025-10-02__17-49-04-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-02__17-49-04-000_cotton/epar_merged.csv (10987 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-02__17-49-04-000_cotton/par_merged.csv (10983 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-02__17-49-04-000_cotton/weather_station_merged.csv (950 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-02__17-49-04-000_cotton/all_sensors_long.csv (22920 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-10-06__17-15-53-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-10-06__17-15-53-000_cotton/MeteorologicalSensor-2025-10-06__17-15-53-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-10-06__17-15-53-000_cotton/MeteorologicalSensor-2025-10-06__17-15-53-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-06__17-15-53-000_cotton/epar_merged.csv (10975 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-06__17-15-53-000_cotton/par_merged.csv (10972 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-06__17-15-53-000_cotton/weather_station_merged.csv (947 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-06__17-15-53-000_cotton/all_sensors_long.csv (22894 rows)\n",
      "[INFO] Processing MeteorologicalSensor-2025-10-09__17-07-15-000_cotton.tar.gz ...\n",
      "[DEBUG] sensor_root: workdir/MeteorologicalSensor-2025-10-09__17-07-15-000_cotton/MeteorologicalSensor-2025-10-09__17-07-15-000_cotton/meteorological_sensor\n",
      "[INFO] Found 166 plot directories in workdir/MeteorologicalSensor-2025-10-09__17-07-15-000_cotton/MeteorologicalSensor-2025-10-09__17-07-15-000_cotton/meteorological_sensor\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-09__17-07-15-000_cotton/epar_merged.csv (10979 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-09__17-07-15-000_cotton/par_merged.csv (10979 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-09__17-07-15-000_cotton/weather_station_merged.csv (950 rows)\n",
      "[INFO] Wrote outputs/MeteorologicalSensor-2025-10-09__17-07-15-000_cotton/all_sensors_long.csv (22908 rows)\n",
      "[INFO] Wrote outputs/_GLOBAL/epar_GLOBAL_merged.csv (515384 rows)\n",
      "[INFO] Wrote outputs/_GLOBAL/par_GLOBAL_merged.csv (515144 rows)\n",
      "[INFO] Wrote outputs/_GLOBAL/weather_station_GLOBAL_merged.csv (41988 rows)\n",
      "[INFO] Wrote outputs/_GLOBAL/all_sensors_GLOBAL_long.csv (1072516 rows)\n"
     ]
    }
   ],
   "source": [
    "process_all_tarballs(\n",
    "    input_dir=Path('./inputs/MeteorologicalSensor'),\n",
    "    work_dir=Path('./workdir'),\n",
    "    output_dir=Path('./outputs'),\n",
    "    keep_extracted=True,\n",
    "    make_global_merge=False,\n",
    "    dedupe_on_timestamp=not True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a708079f-8209-41b1-b007-2442b95612c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_crop_from_dirname(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Parse crop from tarball-derived directory name:\n",
    "    MeteorologicalSensor-YYYY-MM-DD__HH-MM-SS-sss_<crop>\n",
    "\n",
    "    Returns lowercased crop or None if not found.\n",
    "    \"\"\"\n",
    "    pat = re.compile(\n",
    "        r\"^MeteorologicalSensor-\\d{4}-\\d{2}-\\d{2}__\\d{2}-\\d{2}-\\d{2}-\\d{3}_(?P<crop>[A-Za-z0-9_-]+)$\"\n",
    "    )\n",
    "    m = pat.match(name)\n",
    "    if m:\n",
    "        return m.group(\"crop\").lower()\n",
    "    # Fallback: last underscore segment (best effort)\n",
    "    parts = name.split(\"_\")\n",
    "    return parts[-1].lower() if len(parts) > 1 else None\n",
    "\n",
    "\n",
    "def infer_crop_from_csv(dir_path: Path) -> str:\n",
    "    \"\"\"\n",
    "    If crop isn't in the folder name, infer from the CSV:\n",
    "    prefer 'meta_crop' (added by our merge script), else a 'crop' column if present.\n",
    "    \"\"\"\n",
    "    csv_path = dir_path / \"all_sensors_long.csv\"\n",
    "    if not csv_path.exists():\n",
    "        return None\n",
    "    try:\n",
    "        # Read a small sample to be fast\n",
    "        df = pd.read_csv(csv_path, nrows=200)\n",
    "        for col in [\"meta_crop\", \"crop\"]:\n",
    "            if col in df.columns:\n",
    "                vals = df[col].dropna().astype(str).str.strip().str.lower()\n",
    "                if not vals.empty:\n",
    "                    # Use the most common value (mode); falls back to first if mode fails\n",
    "                    try:\n",
    "                        return vals.mode().iat[0]\n",
    "                    except Exception:\n",
    "                        return vals.iloc[0]\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not infer crop from {csv_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def unique_target_path(dest_dir: Path, original_name: str) -> Path:\n",
    "    \"\"\"\n",
    "    Create a collision-safe target path. If a folder with the same name exists,\n",
    "    append a suffix like '__dup1', '__dup2', ...\n",
    "    \"\"\"\n",
    "    target = dest_dir / original_name\n",
    "    if not target.exists():\n",
    "        return target\n",
    "    suffix = 1\n",
    "    while (dest_dir / f\"{original_name}__dup{suffix}\").exists():\n",
    "        suffix += 1\n",
    "    return dest_dir / f\"{original_name}__dup{suffix}\"\n",
    "\n",
    "\n",
    "def move_outputs_by_crop(outputs_root: Path = Path(\"./outputs\"), dry_run: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Find all subfolders under outputs_root that contain 'all_sensors_long.csv',\n",
    "    determine their crop dynamically, and move them into outputs_root/<crop>/.\n",
    "    \"\"\"\n",
    "    if not outputs_root.exists():\n",
    "        raise FileNotFoundError(f\"Outputs root not found: {outputs_root}\")\n",
    "\n",
    "    moved = []\n",
    "    skipped = []\n",
    "\n",
    "    for d in sorted(outputs_root.iterdir()):\n",
    "        # Consider only directories containing our per-tarball long file\n",
    "        if not d.is_dir():\n",
    "            continue\n",
    "        if d.name == \"_GLOBAL\":\n",
    "            # keep global outputs in place\n",
    "            skipped.append((d, \"skip _GLOBAL\"))\n",
    "            continue\n",
    "        if not (d / \"all_sensors_long.csv\").exists():\n",
    "            # skip folders that aren't tarball result folders\n",
    "            skipped.append((d, \"no all_sensors_long.csv\"))\n",
    "            continue\n",
    "\n",
    "        # If this folder is already inside a crop folder (e.g., outputs/cotton/<tarball_dir>), skip\n",
    "        parent = d.parent\n",
    "        if parent != outputs_root and (parent / \"all_sensors_long.csv\").exists() is False:\n",
    "            # Heuristic: if parent isn't outputs_root and isn't a tarball dir itself, we assume it's already organized\n",
    "            skipped.append((d, f\"already under '{parent.name}'\"))\n",
    "            continue\n",
    "\n",
    "        # Try to parse crop from folder name; fallback to CSV metadata\n",
    "        crop = parse_crop_from_dirname(d.name)\n",
    "        if not crop:\n",
    "            crop = infer_crop_from_csv(d)\n",
    "\n",
    "        if not crop:\n",
    "            print(f\"[WARN] Could not determine crop for {d}. Skipping.\")\n",
    "            skipped.append((d, \"no crop parsed\"))\n",
    "            continue\n",
    "\n",
    "        dest_dir = outputs_root / crop\n",
    "        dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "        target = unique_target_path(dest_dir, d.name)\n",
    "\n",
    "        print(f\"[INFO] {'DRY-RUN:' if dry_run else ''} moving {d} -> {target}\")\n",
    "        if not dry_run:\n",
    "            shutil.move(str(d), str(target))\n",
    "        moved.append((d, target))\n",
    "\n",
    "    print(f\"[INFO] Moved {len(moved)} folders. Skipped {len(skipped)}.\")\n",
    "    if skipped:\n",
    "        for d, reason in skipped[:10]:\n",
    "            print(f\"  - skipped {d.name}: {reason}\")\n",
    "        if len(skipped) > 10:\n",
    "            print(\"  ...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b2f3d32-0475-4ff2-ac65-1e034d6fe423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]  moving outputs/MeteorologicalSensor-2025-05-30__17-14-43-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-05-30__17-14-43-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-05-30__23-10-02-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-05-30__23-10-02-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-02__17-37-04-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-02__17-37-04-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-05__17-27-49-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-05__17-27-49-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-09__17-41-10-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-09__17-41-10-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-13__18-06-09-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-13__18-06-09-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-14__00-16-53-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-14__00-16-53-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-16__17-27-21-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-16__17-27-21-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-18__15-51-51-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-18__15-51-51-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-19__18-09-05-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-19__18-09-05-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-23__17-38-28-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-23__17-38-28-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-25__15-16-37-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-25__15-16-37-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-26__17-54-16-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-26__17-54-16-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-06-30__17-29-09-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-06-30__17-29-09-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-07-01__14-51-20-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-07-01__14-51-20-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-07-03__17-33-44-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-07-03__17-33-44-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-07-07__17-29-47-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-07-07__17-29-47-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-07-10__17-42-32-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-07-10__17-42-32-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-07-14__17-30-42-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-07-14__17-30-42-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-07-16__17-27-47-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-07-16__17-27-47-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-07-21__17-29-15-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-07-21__17-29-15-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-07-24__04-54-57-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-07-24__04-54-57-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-07-24__17-25-09-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-07-24__17-25-09-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-07-25__05-03-06-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-07-25__05-03-06-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-07-30__18-40-16-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-07-30__18-40-16-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-08-01__17-29-20-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-08-01__17-29-20-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-08-04__04-58-54-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-08-04__04-58-54-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-08-04__17-28-08-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-08-04__17-28-08-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-08-05__04-58-30-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-08-05__04-58-30-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-08-08__17-27-29-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-08-08__17-27-29-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-08-11__17-30-12-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-08-11__17-30-12-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-08-14__04-58-19-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-08-14__04-58-19-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-08-14__17-26-54-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-08-14__17-26-54-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-08-15__04-57-00-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-08-15__04-57-00-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-08-18__17-31-03-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-08-18__17-31-03-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-08-22__17-32-06-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-08-22__17-32-06-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-09-10__17-25-27-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-09-10__17-25-27-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-09-11__17-20-09-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-09-11__17-20-09-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-09-15__17-28-14-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-09-15__17-28-14-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-09-18__16-59-50-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-09-18__16-59-50-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-09-22__19-29-02-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-09-22__19-29-02-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-09-24__17-29-20-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-09-24__17-29-20-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-09-25__05-00-04-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-09-25__05-00-04-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-09-26__04-56-17-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-09-26__04-56-17-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-09-30__18-12-11-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-09-30__18-12-11-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-10-02__17-49-04-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-10-02__17-49-04-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-10-06__17-15-53-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-10-06__17-15-53-000_cotton\n",
      "[INFO]  moving outputs/MeteorologicalSensor-2025-10-09__17-07-15-000_cotton -> outputs/cotton/MeteorologicalSensor-2025-10-09__17-07-15-000_cotton\n",
      "[INFO] Moved 48 folders. Skipped 2.\n",
      "  - skipped .ipynb_checkpoints: no all_sensors_long.csv\n",
      "  - skipped cotton: no all_sensors_long.csv\n"
     ]
    }
   ],
   "source": [
    "move_outputs_by_crop(outputs_root=Path('./outputs'), dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "37886876-588e-42af-9e09-a420b2305843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Authorized uses only. All activity may be monitored and reported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running recursive pre-scan... pre-scan complete... transferring data...\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton:\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-07-24__17-25-09-000_cotton:\n",
      "0/193 -  0.00% of files done   0.000/454.109 MB -  0.00% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.663 MB   2025-12-19.10:41:02\n",
      "   all_sensors_long.csv            4.663 MB | 1.482 sec | 0 thr |  3.146 MB/s\n",
      "1/193 -  0.52% of files done   4.663/454.109 MB -  1.03% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.228 MB   2025-12-19.10:41:04\n",
      "   weather_station_merged.cs       0.228 MB | 0.787 sec | 0 thr |  0.290 MB/s\n",
      "2/193 -  1.04% of files done   4.891/454.109 MB -  1.08% of file sizes done\n",
      "Processing epar_merged.csv - 2.117 MB   2025-12-19.10:41:04\n",
      "   epar_merged.csv                 2.117 MB | 1.215 sec | 0 thr |  1.742 MB/s\n",
      "3/193 -  1.55% of files done   7.007/454.109 MB -  1.54% of file sizes done\n",
      "Processing par_merged.csv - 2.058 MB   2025-12-19.10:41:06\n",
      "   par_merged.csv                  2.058 MB | 0.854 sec | 0 thr |  2.412 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-06-09__17-41-10-000_cotton:\n",
      "4/193 -  2.07% of files done   9.066/454.109 MB -  2.00% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.951 MB   2025-12-19.10:41:14\n",
      "   all_sensors_long.csv            4.951 MB | 1.311 sec | 0 thr |  3.776 MB/s\n",
      "5/193 -  2.59% of files done   14.017/454.109 MB -  3.09% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.240 MB   2025-12-19.10:41:16\n",
      "   weather_station_merged.cs       0.240 MB | 0.910 sec | 0 thr |  0.264 MB/s\n",
      "6/193 -  3.11% of files done   14.257/454.109 MB -  3.14% of file sizes done\n",
      "Processing epar_merged.csv - 2.250 MB   2025-12-19.10:41:17\n",
      "   epar_merged.csv                 2.250 MB | 1.005 sec | 0 thr |  2.240 MB/s\n",
      "7/193 -  3.63% of files done   16.507/454.109 MB -  3.64% of file sizes done\n",
      "Processing par_merged.csv - 2.185 MB   2025-12-19.10:41:18\n",
      "   par_merged.csv                  2.185 MB | 1.511 sec | 0 thr |  1.447 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-06-23__17-38-28-000_cotton:\n",
      "8/193 -  4.15% of files done   18.692/454.109 MB -  4.12% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.946 MB   2025-12-19.10:41:27\n",
      "   all_sensors_long.csv            4.946 MB | 0.959 sec | 0 thr |  5.158 MB/s\n",
      "9/193 -  4.66% of files done   23.639/454.109 MB -  5.21% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.243 MB   2025-12-19.10:41:28\n",
      "   weather_station_merged.cs       0.243 MB | 0.892 sec | 0 thr |  0.272 MB/s\n",
      "10/193 -  5.18% of files done   23.881/454.109 MB -  5.26% of file sizes done\n",
      "Processing epar_merged.csv - 2.239 MB   2025-12-19.10:41:28\n",
      "   epar_merged.csv                 2.239 MB | 0.947 sec | 0 thr |  2.365 MB/s\n",
      "11/193 -  5.70% of files done   26.120/454.109 MB -  5.75% of file sizes done\n",
      "Processing par_merged.csv - 2.189 MB   2025-12-19.10:41:29\n",
      "   par_merged.csv                  2.189 MB | 0.785 sec | 0 thr |  2.789 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-08-15__04-57-00-000_cotton:\n",
      "12/193 -  6.22% of files done   28.309/454.109 MB -  6.23% of file sizes done\n",
      "Processing all_sensors_long.csv - 1.162 MB   2025-12-19.10:41:37\n",
      "   all_sensors_long.csv            1.162 MB | 0.860 sec | 0 thr |  1.351 MB/s\n",
      "13/193 -  6.74% of files done   29.471/454.109 MB -  6.49% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.012 MB   2025-12-19.10:41:38\n",
      "   weather_station_merged.cs       0.012 MB | 0.872 sec | 0 thr |  0.013 MB/s\n",
      "14/193 -  7.25% of files done   29.483/454.109 MB -  6.49% of file sizes done\n",
      "Processing epar_merged.csv - 0.544 MB   2025-12-19.10:41:39\n",
      "   epar_merged.csv                 0.544 MB | 0.761 sec | 0 thr |  0.715 MB/s\n",
      "15/193 -  7.77% of files done   30.027/454.109 MB -  6.61% of file sizes done\n",
      "Processing par_merged.csv - 0.538 MB   2025-12-19.10:41:40\n",
      "   par_merged.csv                  0.538 MB | 0.743 sec | 0 thr |  0.725 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-06-13__18-06-09-000_cotton:\n",
      "16/193 -  8.29% of files done   30.565/454.109 MB -  6.73% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.959 MB   2025-12-19.10:41:48\n",
      "   all_sensors_long.csv            4.959 MB | 0.808 sec | 0 thr |  6.141 MB/s\n",
      "17/193 -  8.81% of files done   35.524/454.109 MB -  7.82% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.244 MB   2025-12-19.10:41:49\n",
      "   weather_station_merged.cs       0.244 MB | 0.842 sec | 0 thr |  0.290 MB/s\n",
      "18/193 -  9.33% of files done   35.768/454.109 MB -  7.88% of file sizes done\n",
      "Processing epar_merged.csv - 2.251 MB   2025-12-19.10:41:50\n",
      "   epar_merged.csv                 2.251 MB | 0.916 sec | 0 thr |  2.457 MB/s\n",
      "19/193 -  9.84% of files done   38.019/454.109 MB -  8.37% of file sizes done\n",
      "Processing par_merged.csv - 2.188 MB   2025-12-19.10:41:50\n",
      "   par_merged.csv                  2.188 MB | 0.977 sec | 0 thr |  2.239 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-09-24__17-29-20-000_cotton:\n",
      "20/193 - 10.36% of files done   40.207/454.109 MB -  8.85% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.951 MB   2025-12-19.10:41:58\n",
      "   all_sensors_long.csv            4.951 MB | 0.839 sec | 0 thr |  5.898 MB/s\n",
      "21/193 - 10.88% of files done   45.158/454.109 MB -  9.94% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.240 MB   2025-12-19.10:41:59\n",
      "   weather_station_merged.cs       0.240 MB | 0.804 sec | 0 thr |  0.299 MB/s\n",
      "22/193 - 11.40% of files done   45.399/454.109 MB - 10.00% of file sizes done\n",
      "Processing epar_merged.csv - 2.247 MB   2025-12-19.10:42:00\n",
      "   epar_merged.csv                 2.247 MB | 0.835 sec | 0 thr |  2.691 MB/s\n",
      "23/193 - 11.92% of files done   47.645/454.109 MB - 10.49% of file sizes done\n",
      "Processing par_merged.csv - 2.188 MB   2025-12-19.10:42:01\n",
      "   par_merged.csv                  2.188 MB | 0.934 sec | 0 thr |  2.341 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-06-05__17-27-49-000_cotton:\n",
      "24/193 - 12.44% of files done   49.833/454.109 MB - 10.97% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.944 MB   2025-12-19.10:42:09\n",
      "   all_sensors_long.csv            4.944 MB | 1.002 sec | 0 thr |  4.933 MB/s\n",
      "25/193 - 12.95% of files done   54.778/454.109 MB - 12.06% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.241 MB   2025-12-19.10:42:10\n",
      "   weather_station_merged.cs       0.241 MB | 1.052 sec | 0 thr |  0.229 MB/s\n",
      "26/193 - 13.47% of files done   55.019/454.109 MB - 12.12% of file sizes done\n",
      "Processing epar_merged.csv - 2.241 MB   2025-12-19.10:42:11\n",
      "   epar_merged.csv                 2.241 MB | 0.800 sec | 0 thr |  2.802 MB/s\n",
      "27/193 - 13.99% of files done   57.260/454.109 MB - 12.61% of file sizes done\n",
      "Processing par_merged.csv - 2.187 MB   2025-12-19.10:42:12\n",
      "   par_merged.csv                  2.187 MB | 0.831 sec | 0 thr |  2.633 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-08-14__04-58-19-000_cotton:\n",
      "28/193 - 14.51% of files done   59.447/454.109 MB - 13.09% of file sizes done\n",
      "Processing all_sensors_long.csv - 2.080 MB   2025-12-19.10:42:20\n",
      "   all_sensors_long.csv            2.080 MB | 0.797 sec | 0 thr |  2.610 MB/s\n",
      "29/193 - 15.03% of files done   61.526/454.109 MB - 13.55% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.023 MB   2025-12-19.10:42:21\n",
      "   weather_station_merged.cs       0.023 MB | 0.819 sec | 0 thr |  0.028 MB/s\n",
      "30/193 - 15.54% of files done   61.549/454.109 MB - 13.55% of file sizes done\n",
      "Processing epar_merged.csv - 0.981 MB   2025-12-19.10:42:22\n",
      "   epar_merged.csv                 0.981 MB | 0.765 sec | 0 thr |  1.282 MB/s\n",
      "31/193 - 16.06% of files done   62.530/454.109 MB - 13.77% of file sizes done\n",
      "Processing par_merged.csv - 0.954 MB   2025-12-19.10:42:23\n",
      "   par_merged.csv                  0.954 MB | 0.754 sec | 0 thr |  1.266 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-07-24__04-54-57-000_cotton:\n",
      "32/193 - 16.58% of files done   63.484/454.109 MB - 13.98% of file sizes done\n",
      "Processing all_sensors_long.csv - 2.044 MB   2025-12-19.10:42:31\n",
      "   all_sensors_long.csv            2.044 MB | 0.810 sec | 0 thr |  2.524 MB/s\n",
      "33/193 - 17.10% of files done   65.528/454.109 MB - 14.43% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.023 MB   2025-12-19.10:42:31\n",
      "   weather_station_merged.cs       0.023 MB | 0.826 sec | 0 thr |  0.028 MB/s\n",
      "34/193 - 17.62% of files done   65.551/454.109 MB - 14.44% of file sizes done\n",
      "Processing epar_merged.csv - 0.948 MB   2025-12-19.10:42:32\n",
      "   epar_merged.csv                 0.948 MB | 0.766 sec | 0 thr |  1.238 MB/s\n",
      "35/193 - 18.13% of files done   66.500/454.109 MB - 14.64% of file sizes done\n",
      "Processing par_merged.csv - 0.952 MB   2025-12-19.10:42:33\n",
      "   par_merged.csv                  0.952 MB | 0.794 sec | 0 thr |  1.198 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-09-15__17-28-14-000_cotton:\n",
      "36/193 - 18.65% of files done   67.451/454.109 MB - 14.85% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.959 MB   2025-12-19.10:42:42\n",
      "   all_sensors_long.csv            4.959 MB | 0.853 sec | 0 thr |  5.813 MB/s\n",
      "37/193 - 19.17% of files done   72.411/454.109 MB - 15.95% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.242 MB   2025-12-19.10:42:42\n",
      "   weather_station_merged.cs       0.242 MB | 0.732 sec | 0 thr |  0.331 MB/s\n",
      "38/193 - 19.69% of files done   72.653/454.109 MB - 16.00% of file sizes done\n",
      "Processing epar_merged.csv - 2.251 MB   2025-12-19.10:42:43\n",
      "   epar_merged.csv                 2.251 MB | 0.858 sec | 0 thr |  2.625 MB/s\n",
      "39/193 - 20.21% of files done   74.904/454.109 MB - 16.49% of file sizes done\n",
      "Processing par_merged.csv - 2.191 MB   2025-12-19.10:42:44\n",
      "   par_merged.csv                  2.191 MB | 0.846 sec | 0 thr |  2.589 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-08-01__17-29-20-000_cotton:\n",
      "40/193 - 20.73% of files done   77.094/454.109 MB - 16.98% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.954 MB   2025-12-19.10:42:52\n",
      "   all_sensors_long.csv            4.954 MB | 0.971 sec | 0 thr |  5.101 MB/s\n",
      "41/193 - 21.24% of files done   82.048/454.109 MB - 18.07% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.243 MB   2025-12-19.10:42:53\n",
      "   weather_station_merged.cs       0.243 MB | 0.823 sec | 0 thr |  0.295 MB/s\n",
      "42/193 - 21.76% of files done   82.291/454.109 MB - 18.12% of file sizes done\n",
      "Processing epar_merged.csv - 2.250 MB   2025-12-19.10:42:54\n",
      "   epar_merged.csv                 2.250 MB | 0.931 sec | 0 thr |  2.415 MB/s\n",
      "43/193 - 22.28% of files done   84.541/454.109 MB - 18.62% of file sizes done\n",
      "Processing par_merged.csv - 2.186 MB   2025-12-19.10:42:55\n",
      "   par_merged.csv                  2.186 MB | 0.888 sec | 0 thr |  2.463 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-07-30__18-40-16-000_cotton:\n",
      "44/193 - 22.80% of files done   86.727/454.109 MB - 19.10% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.952 MB   2025-12-19.10:43:03\n",
      "   all_sensors_long.csv            4.952 MB | 0.815 sec | 0 thr |  6.077 MB/s\n",
      "45/193 - 23.32% of files done   91.679/454.109 MB - 20.19% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.241 MB   2025-12-19.10:43:04\n",
      "   weather_station_merged.cs       0.241 MB | 0.709 sec | 0 thr |  0.340 MB/s\n",
      "46/193 - 23.83% of files done   91.920/454.109 MB - 20.24% of file sizes done\n",
      "Processing epar_merged.csv - 2.248 MB   2025-12-19.10:43:05\n",
      "   epar_merged.csv                 2.248 MB | 0.976 sec | 0 thr |  2.303 MB/s\n",
      "47/193 - 24.35% of files done   94.168/454.109 MB - 20.74% of file sizes done\n",
      "Processing par_merged.csv - 2.187 MB   2025-12-19.10:43:06\n",
      "   par_merged.csv                  2.187 MB | 0.822 sec | 0 thr |  2.659 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-06-25__15-16-37-000_cotton:\n",
      "48/193 - 24.87% of files done   96.355/454.109 MB - 21.22% of file sizes done\n",
      "Processing all_sensors_long.csv - 8.616 MB   2025-12-19.10:43:14\n",
      "   all_sensors_long.csv            8.616 MB | 0.839 sec | 0 thr | 10.265 MB/s\n",
      "49/193 - 25.39% of files done   104.971/454.109 MB - 23.12% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.418 MB   2025-12-19.10:43:15\n",
      "   weather_station_merged.cs       0.418 MB | 0.806 sec | 0 thr |  0.519 MB/s\n",
      "50/193 - 25.91% of files done   105.390/454.109 MB - 23.21% of file sizes done\n",
      "Processing epar_merged.csv - 3.910 MB   2025-12-19.10:43:16\n",
      "   epar_merged.csv                 3.910 MB | 0.925 sec | 0 thr |  4.225 MB/s\n",
      "51/193 - 26.42% of files done   109.300/454.109 MB - 24.07% of file sizes done\n",
      "Processing par_merged.csv - 3.809 MB   2025-12-19.10:43:17\n",
      "   par_merged.csv                  3.809 MB | 0.917 sec | 0 thr |  4.153 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-05-30__23-10-02-000_cotton:\n",
      "52/193 - 26.94% of files done   113.109/454.109 MB - 24.91% of file sizes done\n",
      "Processing all_sensors_long.csv - 8.493 MB   2025-12-19.10:43:25\n",
      "   all_sensors_long.csv            8.493 MB | 0.851 sec | 0 thr |  9.976 MB/s\n",
      "53/193 - 27.46% of files done   121.602/454.109 MB - 26.78% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.412 MB   2025-12-19.10:43:25\n",
      "   weather_station_merged.cs       0.412 MB | 1.019 sec | 0 thr |  0.404 MB/s\n",
      "54/193 - 27.98% of files done   122.014/454.109 MB - 26.87% of file sizes done\n",
      "Processing epar_merged.csv - 3.845 MB   2025-12-19.10:43:26\n",
      "   epar_merged.csv                 3.845 MB | 0.944 sec | 0 thr |  4.073 MB/s\n",
      "55/193 - 28.50% of files done   125.859/454.109 MB - 27.72% of file sizes done\n",
      "Processing par_merged.csv - 3.759 MB   2025-12-19.10:43:27\n",
      "   par_merged.csv                  3.759 MB | 0.851 sec | 0 thr |  4.420 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-10-02__17-49-04-000_cotton:\n",
      "56/193 - 29.02% of files done   129.618/454.109 MB - 28.54% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.956 MB   2025-12-19.10:43:36\n",
      "   all_sensors_long.csv            4.956 MB | 1.020 sec | 0 thr |  4.857 MB/s\n",
      "57/193 - 29.53% of files done   134.574/454.109 MB - 29.63% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.242 MB   2025-12-19.10:43:37\n",
      "   weather_station_merged.cs       0.242 MB | 0.887 sec | 0 thr |  0.272 MB/s\n",
      "58/193 - 30.05% of files done   134.816/454.109 MB - 29.69% of file sizes done\n",
      "Processing epar_merged.csv - 2.250 MB   2025-12-19.10:43:38\n",
      "   epar_merged.csv                 2.250 MB | 0.864 sec | 0 thr |  2.604 MB/s\n",
      "59/193 - 30.57% of files done   137.066/454.109 MB - 30.18% of file sizes done\n",
      "Processing par_merged.csv - 2.189 MB   2025-12-19.10:43:38\n",
      "   par_merged.csv                  2.189 MB | 0.806 sec | 0 thr |  2.714 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-09-30__18-12-11-000_cotton:\n",
      "60/193 - 31.09% of files done   139.255/454.109 MB - 30.67% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.954 MB   2025-12-19.10:43:47\n",
      "   all_sensors_long.csv            4.954 MB | 0.939 sec | 0 thr |  5.278 MB/s\n",
      "61/193 - 31.61% of files done   144.209/454.109 MB - 31.76% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.242 MB   2025-12-19.10:43:48\n",
      "   weather_station_merged.cs       0.242 MB | 0.832 sec | 0 thr |  0.291 MB/s\n",
      "62/193 - 32.12% of files done   144.451/454.109 MB - 31.81% of file sizes done\n",
      "Processing epar_merged.csv - 2.249 MB   2025-12-19.10:43:48\n",
      "   epar_merged.csv                 2.249 MB | 0.956 sec | 0 thr |  2.352 MB/s\n",
      "63/193 - 32.64% of files done   146.700/454.109 MB - 32.30% of file sizes done\n",
      "Processing par_merged.csv - 2.188 MB   2025-12-19.10:43:49\n",
      "   par_merged.csv                  2.188 MB | 0.830 sec | 0 thr |  2.636 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-07-03__17-33-44-000_cotton:\n",
      "64/193 - 33.16% of files done   148.888/454.109 MB - 32.79% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.957 MB   2025-12-19.10:43:57\n",
      "   all_sensors_long.csv            4.957 MB | 1.023 sec | 0 thr |  4.845 MB/s\n",
      "65/193 - 33.68% of files done   153.845/454.109 MB - 33.88% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.241 MB   2025-12-19.10:43:58\n",
      "   weather_station_merged.cs       0.241 MB | 0.777 sec | 0 thr |  0.311 MB/s\n",
      "66/193 - 34.20% of files done   154.087/454.109 MB - 33.93% of file sizes done\n",
      "Processing epar_merged.csv - 2.252 MB   2025-12-19.10:43:59\n",
      "   epar_merged.csv                 2.252 MB | 0.878 sec | 0 thr |  2.564 MB/s\n",
      "67/193 - 34.72% of files done   156.338/454.109 MB - 34.43% of file sizes done\n",
      "Processing par_merged.csv - 2.189 MB   2025-12-19.10:44:00\n",
      "   par_merged.csv                  2.189 MB | 0.789 sec | 0 thr |  2.775 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-08-14__17-26-54-000_cotton:\n",
      "68/193 - 35.23% of files done   158.527/454.109 MB - 34.91% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.956 MB   2025-12-19.10:44:08\n",
      "   all_sensors_long.csv            4.956 MB | 0.973 sec | 0 thr |  5.092 MB/s\n",
      "69/193 - 35.75% of files done   163.483/454.109 MB - 36.00% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.242 MB   2025-12-19.10:44:09\n",
      "   weather_station_merged.cs       0.242 MB | 0.772 sec | 0 thr |  0.313 MB/s\n",
      "70/193 - 36.27% of files done   163.725/454.109 MB - 36.05% of file sizes done\n",
      "Processing epar_merged.csv - 2.252 MB   2025-12-19.10:44:10\n",
      "   epar_merged.csv                 2.252 MB | 0.917 sec | 0 thr |  2.456 MB/s\n",
      "71/193 - 36.79% of files done   165.977/454.109 MB - 36.55% of file sizes done\n",
      "Processing par_merged.csv - 2.186 MB   2025-12-19.10:44:11\n",
      "   par_merged.csv                  2.186 MB | 0.820 sec | 0 thr |  2.667 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-07-16__17-27-47-000_cotton:\n",
      "72/193 - 37.31% of files done   168.163/454.109 MB - 37.03% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.869 MB   2025-12-19.10:44:19\n",
      "   all_sensors_long.csv            4.869 MB | 0.822 sec | 0 thr |  5.922 MB/s\n",
      "73/193 - 37.82% of files done   173.032/454.109 MB - 38.10% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.242 MB   2025-12-19.10:44:20\n",
      "   weather_station_merged.cs       0.242 MB | 0.783 sec | 0 thr |  0.310 MB/s\n",
      "74/193 - 38.34% of files done   173.274/454.109 MB - 38.16% of file sizes done\n",
      "Processing epar_merged.csv - 2.164 MB   2025-12-19.10:44:21\n",
      "   epar_merged.csv                 2.164 MB | 0.919 sec | 0 thr |  2.354 MB/s\n",
      "75/193 - 38.86% of files done   175.439/454.109 MB - 38.63% of file sizes done\n",
      "Processing par_merged.csv - 2.187 MB   2025-12-19.10:44:22\n",
      "   par_merged.csv                  2.187 MB | 0.925 sec | 0 thr |  2.363 MB/s\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor/cotton/MeteorologicalSensor-2025-08-04__17-28-08-000_cotton:\n",
      "76/193 - 39.38% of files done   177.626/454.109 MB - 39.12% of file sizes done\n",
      "Processing all_sensors_long.csv - 4.921 MB   2025-12-19.10:44:30\n",
      "   all_sensors_long.csv            4.921 MB | 0.853 sec | 0 thr |  5.769 MB/s\n",
      "77/193 - 39.90% of files done   182.547/454.109 MB - 40.20% of file sizes done\n",
      "Processing weather_station_merged.csv - 0.240 MB   2025-12-19.10:44:31\n",
      "   weather_station_merged.cs       0.240 MB | 0.767 sec | "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m cyverse_dir_l1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_1/MeteorologicalSensor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m cmd1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124miput -rkPVT ./outputs/* \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcyverse_dir_l1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m upload \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mssh filexfer \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcd \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcwd\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m && \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcmd1\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m && exit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(upload\u001b[38;5;241m.\u001b[39mstdout)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupload complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/subprocess.py:495\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 495\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    497\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/subprocess.py:1020\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/subprocess.py:1083\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1085\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/subprocess.py:1806\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 1806\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   1808\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   1809\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   1810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m/opt/ohpc/pub/apps/python/3.8.12/lib/python3.8/subprocess.py:1764\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1764\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_flags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   1766\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   1768\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   1769\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cmd1 = f'iput -rkPVT ./outputs/* {cyverse_dir_l1}'\n",
    "upload = sp.run(f\"ssh filexfer 'cd {cwd} && {cmd1} && exit'\", shell=True)\n",
    "print(upload.stdout)\n",
    "print(\"upload complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a6b5e4d-b64a-449c-a094-a96fd202bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _dedupe_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Deduplicate with preference: timestamp -> date_int -> date.\"\"\"\n",
    "    if \"timestamp\" in df.columns and df[\"timestamp\"].notna().any():\n",
    "        key_cols = [c for c in [\"tarball_name\", \"sensor_type\", \"plot_id\", \"timestamp\"] if c in df.columns]\n",
    "        return df.drop_duplicates(subset=key_cols)\n",
    "    if \"date_int\" in df.columns:\n",
    "        key_cols = [c for c in [\"tarball_name\", \"sensor_type\", \"plot_id\", \"date_int\"] if c in df.columns]\n",
    "        return df.drop_duplicates(subset=key_cols)\n",
    "    if \"date\" in df.columns:\n",
    "        key_cols = [c for c in [\"tarball_name\", \"sensor_type\", \"plot_id\", \"date\"] if c in df.columns]\n",
    "        return df.drop_duplicates(subset=key_cols)\n",
    "    # Fallback: drop exact duplicates\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "\n",
    "def _ensure_tarball_name(df: pd.DataFrame, source_dir_name: str) -> pd.DataFrame:\n",
    "    \"\"\"Ensure 'tarball_name' column exists; if missing/empty, fill with the parent folder name.\"\"\"\n",
    "    if \"tarball_name\" not in df.columns or df[\"tarball_name\"].isna().all():\n",
    "        df[\"tarball_name\"] = source_dir_name\n",
    "    return df\n",
    "\n",
    "\n",
    "def combine_one_crop(\n",
    "    crop_dir: Path,\n",
    "    output_subdir_name: str = \"_COMBINED\",\n",
    "    output_filename_template: str = \"all_sensors_{crop}.csv\",\n",
    "    dedupe_on_timestamp: bool = True,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Combine all 'all_sensors_long.csv' files found under crop_dir (recursively)\n",
    "    and write a single combined CSV under crop_dir/output_subdir_name/.\n",
    "    Returns the path to the written file, or raises if nothing found.\n",
    "    \"\"\"\n",
    "    crop = crop_dir.name\n",
    "    files = sorted(crop_dir.rglob(\"all_sensors_long.csv\"))\n",
    "\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No 'all_sensors_long.csv' files found under {crop_dir}\")\n",
    "\n",
    "    print(f\"[INFO] ({crop}) found {len(files)} files to combine.\")\n",
    "\n",
    "    frames = []\n",
    "    for f in files:\n",
    "        try:\n",
    "            df = pd.read_csv(f)  # our outputs were written by pandas -> comma-separated\n",
    "            df = _ensure_tarball_name(df, source_dir_name=f.parent.name)\n",
    "            frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] ({crop}) failed to read {f}: {e}\")\n",
    "\n",
    "    if not frames:\n",
    "        raise RuntimeError(f\"({crop}) no readable 'all_sensors_long.csv' files.\")\n",
    "\n",
    "    combined = pd.concat(frames, axis=0, ignore_index=True)\n",
    "\n",
    "    if dedupe_on_timestamp:\n",
    "        before = len(combined)\n",
    "        combined = _dedupe_df(combined)\n",
    "        after = len(combined)\n",
    "        print(f\"[INFO] ({crop}) deduped rows: {before - after} removed; {after} remain.\")\n",
    "\n",
    "    # Write result\n",
    "    out_dir = crop_dir / output_subdir_name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / output_filename_template.format(crop=crop)\n",
    "    combined.to_csv(out_path, index=False)\n",
    "    print(f\"[INFO] ({crop}) wrote combined CSV: {out_path} ({len(combined)} rows)\")\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def combine_all_crops(\n",
    "    outputs_root: Path = Path(\"./outputs\"),\n",
    "    output_subdir_name: str = \"_COMBINED\",\n",
    "    output_filename_template: str = \"all_sensors_{crop}.csv\",\n",
    "    dedupe_on_timestamp: bool = True,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Iterate over all crop directories under outputs_root and combine their\n",
    "    'all_sensors_long.csv' files into one per crop.\n",
    "    \"\"\"\n",
    "    if not outputs_root.exists():\n",
    "        raise FileNotFoundError(f\"Outputs root not found: {outputs_root}\")\n",
    "\n",
    "    # A crop directory is any immediate subdirectory of outputs_root\n",
    "    # that is not special (_GLOBAL) and contains per-tarball results.\n",
    "    crop_dirs = [\n",
    "        d for d in sorted(outputs_root.iterdir())\n",
    "        if d.is_dir() and d.name != \"_GLOBAL\"\n",
    "    ]\n",
    "\n",
    "    if not crop_dirs:\n",
    "        print(f\"[INFO] No crop directories found under {outputs_root}. Did you run the organizer?\")\n",
    "        return\n",
    "\n",
    "    combined_paths = []\n",
    "    for crop_dir in crop_dirs:\n",
    "        # Skip directories that don't contain any 'all_sensors_long.csv'\n",
    "        if not list(crop_dir.rglob(\"all_sensors_long.csv\")):\n",
    "            print(f\"[WARN] Skipping {crop_dir} (no all_sensors_long.csv found).\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            out_path = combine_one_crop(\n",
    "                crop_dir=crop_dir,\n",
    "                output_subdir_name=output_subdir_name,\n",
    "                output_filename_template=output_filename_template,\n",
    "                dedupe_on_timestamp=dedupe_on_timestamp,\n",
    "            )\n",
    "            combined_paths.append(out_path)\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Failed combining for crop '{crop_dir.name}': {e}\")\n",
    "\n",
    "    print(f\"[INFO] Completed. Wrote {len(combined_paths)} combined crop files.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5129be6b-f544-45bc-84b6-702c6aceb942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Skipping outputs/.ipynb_checkpoints (no all_sensors_long.csv found).\n",
      "[INFO] (cotton) found 48 files to combine.\n",
      "[INFO] (cotton) deduped rows: 0 removed; 1072516 remain.\n",
      "[INFO] (cotton) wrote combined CSV: outputs/cotton/_COMBINED/all_sensors_long_merged.csv (1072516 rows)\n",
      "[INFO] Completed. Wrote 1 combined crop files.\n"
     ]
    }
   ],
   "source": [
    "# Combine all 'all_sensors_long.csv' per crop under ./outputs into single per-crop CSVs.\n",
    "combine_all_crops(\n",
    "        outputs_root=Path('./outputs'),\n",
    "        output_subdir_name=\"_COMBINED\",\n",
    "        output_filename_template=\"all_sensors_long_merged.csv\",\n",
    "        dedupe_on_timestamp=not False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b019b38-6643-407c-bce7-64c6a0c79304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved: outputs/cotton/_COMBINED/all_sensors_long_merged.csv -> outputs_merged/cotton/all_sensors_long_merged.csv\n"
     ]
    }
   ],
   "source": [
    "src_root = Path(\"./outputs\")\n",
    "dst_root = Path(\"./outputs_merged\")\n",
    "\n",
    "for crop_dir in src_root.iterdir():\n",
    "    if not crop_dir.is_dir() or crop_dir.name == \"_GLOBAL\":\n",
    "        continue\n",
    "    src_file = crop_dir / \"_COMBINED\" / \"all_sensors_long_merged.csv\"\n",
    "    if src_file.exists():\n",
    "        dest_dir = dst_root / crop_dir.name\n",
    "        dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "        dst_file = dest_dir / src_file.name  # keep original name\n",
    "        shutil.move(str(src_file), str(dst_file))\n",
    "        print(f\"Moved: {src_file} -> {dst_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2858305b-1193-40d2-8b9e-97df88e4cea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Authorized uses only. All activity may be monitored and reported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running recursive pre-scan... pre-scan complete... transferring data...\n",
      "C- /iplant/home/shared/phytooracle/season_19_sorghum_cotton_yr_2025/level_2/MeteorologicalSensor/cotton:\n",
      "0/1 -  0.00% of files done   0.000/230.951 MB -  0.00% of file sizes done\n",
      "Processing all_sensors_long_merged.csv - 230.951 MB   2025-12-19.11:09:50\n",
      "From server: NumThreads=3, addr:r03c05u01-cereus.cyverse.org, port:20049, cookie=31182394\n",
      "all_sensors_long_merged.csv - 80.000/230.951 MB - 34.64% done   2025-12-19.11:09:51\n",
      "all_sensors_long_merged.csv - 230.951/230.951 MB - 100.00% done   2025-12-19.11:09:51\n",
      "   all_sensors_long_merged.c     230.951 MB | 3.084 sec | 3 thr | 74.897 MB/s\n",
      "None\n",
      "upload complete\n"
     ]
    }
   ],
   "source": [
    "cmd1 = f'iput -rkPVT ./outputs_merged/* {cyverse_dir_l2}'\n",
    "upload = sp.run(f\"ssh filexfer 'cd {cwd} && {cmd1} && exit'\", shell=True)\n",
    "print(upload.stdout)\n",
    "print(\"upload complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af4f40e-fb50-4fb9-ae82-8b410eb123e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7ba4a9-b647-406c-8309-cfe93409441d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
